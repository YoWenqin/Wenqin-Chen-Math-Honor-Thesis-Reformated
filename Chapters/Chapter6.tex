% Chapter Template

\chapter{Classification of Entanglement} % Main chapter title

\label{Chapter6-classification of entanglement} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{"actual entanglement".jpg}
    \caption{The First-Ever Photo of Quantum Entanglement captured by physicists at the University of Glasgow. \cite{moreau2019imaging}}
    \label{fig:actual entanglemen}
\end{figure}

When two particles are entangled, their states are so correlated that interacting with one immediately affects the other, even if they are far apart in space.  It is no wonder that Albert Einstein once described entanglement as "spooky action at a distance". While at this point we have defined entanglement (see {\bf{Definition}} \ref{definition: entanglement with state vector} and \textbf{Definition \ref{def: entanglement with density matrix}}) and used its properties (in the E91 Protocol laid out in \textbf{Section \ref{section: e91}}), it is natural to wonder {\emph{exactly}} when a composite state in $\mathbb{C}^n \otimes \mathbb{C}^n$ is entangled.
Are all entangled systems equivalent, or are there some systems that are more entangled than others? In this chapter we answer these questions.


We will begin with a mathematical classification of when a 2-qudit state is a tensor product of two vectors and determine to what extent Alice's vector and Bob's vector are correlated. In the case that Alice's and Bob's vectors are highly correlated, we then examine how Bob can use this correlation to make a one-time pad. 
% We will begin with a mathematical classification of when a vector in a tensor product of two vector spaces is a product of two vectors. We apply this to the situation when Alice and Bob share a $2$-qudit quantum state in $\mathbb{C}^n \otimes \mathbb{C}^n$. When this is the case, we first determine exactly when and to what extent the vectors on Alice's and Bob's side of the tensor product are correlated. If Alice and Bob's side of 
% We then use this idea to 


When Alice and Bob each have a system with state space ${\mathbb{C}}^n$, we know that their composite system will have state space ${\mathbb{C}}^n \otimes {\mathbb{C}}^n={\mathbb{C}}^{n^2}$ by Postulate 4 in \textbf{Chapter \ref{Chapter3-postulates}}. If $\ket{\psi}$ is the state vector for their composite system, the convention is to think of all terms on the left-hand side of the tensor product symbol as representing Alice's system, and all terms on the right-hand side as representing Bob's system.  

In the next Section we show that the rank of a matrix associated to a composite state $\ket{\psi}$ measures how entangled Alice's and Bob's systems are.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\pagebreak

\section{Rank of Coefficient Matrix and the Strength of Entanglement}

We begin will a purely mathematical proposition which characterizes precisely when a vector in the tensor product of two vector spaces is a product of two vectors.

\begin{prop}
\label{rank prop}
Let $\ket{\psi}$ be a state in $\mathbb{C}^n \otimes \mathbb{C}^n$, and let $S=\{\ket{e_i}\}$ be the standard basis for $\mathbb{C}^n$. Define the coefficient matrix $M(\ket{\psi})$ by
\begin{equation}
M(\ket{\psi})=(a_{i,j}) \textrm{, where}\ket{\psi}=\sum\limits_{i,j}a_{i,j}|e_i e_j\rangle . 
\end{equation}
Also, set $S(\ket{\psi})=\{m\in \mathbb{N}: \ket{\psi}=\sum_{i=1}^m\ket{v_i w_i}, for \ket{v_i}, \ket{w_i} \in \mathbb{C}^n\}$.\\  Then, $rank(M(\ket{\psi}))=\textrm{min} (S(\ket{\psi})$.
\end{prop}

Notice in particular, that if $rank(M(\ket{\psi}))=1$, then there exist vectors $\ket{v_1}, \ket{w_1} \in \mathbb{C}^n$ with $\ket{\psi}=\ket{v_1}\ket{w_1}$.  Thus as a Corollary of {\bf{Proposition}} \ref{rank prop} we obtain a classification of entangled states.
\begin{corollary}
If $rank(M(\ket{\psi}))=1$, then the state $\ket{\psi}$ is separable. Otherwise, $\ket{\psi}$ is entangled.
\end{corollary}

While the Proposition shows us that the rank of the coefficient matrix tells us whether or not $\ket{\psi}$ is entangled, we will later see that it is also a measure of {\emph{how}} entangled a composite system is. That is, we will show that the rank indicates the strength of the {\emph{correlation}} between Bob's and Alice's parts of the composite system.

Before we proceed to the rest of the discussion on the connection between rank and entanglement, let's first prove the following Lemma we need in the proof of \textbf{Proposition \ref{rank prop}}.

\begin{lemma}
\label{independence lemma}
Let $k=min S(\ket{\psi})$, and suppose $\ket{\psi}=\sum\limits_{i=1}^k \ket{v_iw_i}$.  Then, the sets $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ are both linearly independent.
\end{lemma}

\begin{proof}
For a contradiction, let $k, \ket{\psi}, \ket{v_i}, \ket{w_i}$ be as above, and suppose that $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ is linearly dependent. Then, without loss of generality, say $\ket{v_k} \in span\{\ket{v_1}, \ket{v_2},...\ket{v_{k-1}}\}$. Then, $\ket{v_k}=\sum\limits_{i=1}^{k-1} a_i \ket{v_i}$, for constants $a_i \in \mathbb{C}$, and
\begin{eqnarray*}
\ket{\psi}&=&\sum\limits_{i=1}^{k-1} \ket{v_i w_i} + \ket{v_k w_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \left(\sum_{i=1}^{k-1} a_i\ket{v_i}\right) \otimes \ket{w_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \sum_{i=1}^{k-1} a_i\ket{v_iw_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i} \otimes (\ket{w_i}+a_i\ket{w_k}).\\
\end{eqnarray*}

Therefore $(k-1) \in S(\ket{\psi})$, contradicting the minimality of $k$.  Thus, $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_m}\}$ are linearly independent as required.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{rank prop}}.

\begin{proof}
Let $k=min(S(\ket{\psi}))$ and say $\ket{\psi}=\sum\limits_{i=1}^k \ket{v_i w_i}$. By Lemma \ref{independence lemma}, $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ are linearly independent.  We now extend each linearly independent set to bases for $\mathbb{C}^n$. Thus, let $B=\{\ket{v_1}, \ket{v_2},...,\ket{v_k}, \ket{v_{k+1}},...,\ket{v_n}\}$ and $B'=\{\ket{w_1}, \ket{w_2},...,\ket{w_n}\}$ be bases, and let $M_{B \otimes B'}(\ket{\psi})$ denote the coefficient matrix of $\ket{\psi}=\sum\limits_{i=1}^{n}\ket{v_i w_i}$ with respect to the basis $B \otimes B'$. That is, $M_{B \otimes B'}(\ket{\psi})$ is the {\emph{coefficient matrix}} corresponding to the basis $\{\ket{v_i w_j} \}$ of ${\mathbb{C}}^{n^2}$.  By inspection, 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_k && 0 \\
0 && 0
\end{pmatrix}$$
so clearly $rank(M_{B \otimes B'}(\ket{\psi}))$ is k.

Thus, we need only show that $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M(\ket{\psi})$.  To do this, we will find two invertible $n \times n$ matrices P, Q with 
\begin{equation}
PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi}).
\end{equation}
Continuing, let $\ket{v_i}=\sum\limits_{j=1}^n v_{ji}\ket{e_j}$, and
$\ket{w_i}=\sum\limits_{j=1}^n w_{ji}\ket{e_j}$.  Since B and B' are both linearly independent, $P=(v_{i,j})$ and $Q=(w_{i,j})$ are both invertible.
% $P=\begin{pmatrix}
% \vert && \vert && \hdots && \vert\\
% \ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
% \vert && \vert && \hdots && \vert\\
% \end{pmatrix}$,\\
% $Q^{-1}=\begin{pmatrix}
% \text{---} && \ket{w_1}^T &&\text{---} \\
% \text{---} && \ket{w_2}^T &&\text{---} \\
% \vdots && \vdots && \vdots \\
% \text{---} && \ket{w_n}^T &&\text{---} \\
% \end{pmatrix}$.


Then, set $(b_{i,j})=PM_{B \otimes B'}(\ket{\psi})Q^{-1}$.  By direct computation, we have that
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

=\begin{pmatrix}
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}
\end{pmatrix}
\begin{pmatrix}
\text{---} && \ket{w_1}^T &&\text{---} \\
\text{---} && \ket{w_2}^T &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \ket{w_k}^T &&\text{---} \\
\text{---} && 0 &&\text{---}
\end{pmatrix}\\
=\begin{pmatrix}
v_{11}w_{11}+\hdots+v_{1k}w_{1k} && v_{11}w_{21}+\hdots+v_{1k}w_{2k} && \hdots && v_{11}w_{n1}+\hdots+v_{1k}w_{nk}\\
v_{21}w_{11}+\hdots+v_{2k}w_{1k} && v_{21}w_{21}+\hdots+v_{2k}w_{2k} && \hdots && v_{21}w_{n1}+\hdots+v_{2k}w_{nk}\\
\vdots && \vdots && \vdots && \vdots\\
v_{n1}w_{11}+\hdots+v_{nk}w_{1k} && v_{n1}w_{21}+\hdots+v_{nk}w_{2k} && \hdots && v_{n1}w_{n1}+\hdots+v_{nk}w_{nk}
\end{pmatrix}

\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{gather*}
    b_{ij}=\sum_{t=1}^k v_{it}w_{jt}
\end{gather*}


On the other hand,
\begin{eqnarray*}
\ket{\psi}&=&\sum_{i=1}^k \ket{v_i w_i}\\
&=&\sum_{i=1}^k \left(\sum_{j=1}^{n} v_{ji} \ket{e_j}) \otimes (\sum_{s=1}^n w_{si}\ket{e_s}\right)\\
&=&\sum_{i=1}^k \sum_{j=1}^{n} \sum_{s=1}^n v_{ji} w_{si} \ket{e_j e_s}\\
\end{eqnarray*}

\noindent
Thus, if $M(\ket{\psi})=(a_{lr})$, then $a_{lr}=\sum_{i=1}^k v_{lk} w_{rk}=b_{lr}$.
So $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi})$.  Therefore, $rank(M(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=k$.
\end{proof}

This established {\bf{Proposition}} \ref{rank prop}. To aid the reader, we include an example of the computation above done in the case when $k=2, n=3$.
\begin{example}
Consider the case where $k=2, n=3$.

Then 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_2 && 0 \\
0 && 0
\end{pmatrix}$$.

We want to show $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M(\ket{\psi})=2$ by finding two $3\  \times 3$ invertible matrices P,Q such that $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi})$.
Let
\begin{gather*}
\ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
\ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\
P=(\ket{v_1}, \ket{v_2}, \ket{v_3})\\
Q^{-1}=(\ket{w_1}, \ket{w_2}, \ket{w_3})^T
\end{gather*}

Then
\begin{eqnarray*}
P M_{B \otimes B'}(\ket{\psi}) Q^{-1}&=&\begin{pmatrix}
v_{11} && v_{12} && v_{13}\\
v_{21} && v_{22} && v_{23}\\
v_{31} && v_{32} && v_{33}
\end{pmatrix}
\begin{pmatrix}
1 && 0 && 0\\
0 && 1 && 0\\
0 && 0 && 0\\
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11} && v_{12} && 0\\
v_{21} && v_{22} && 0\\
v_{31} && v_{32} && 0
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} \\
\end{pmatrix}.
\end{eqnarray*}


% \ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
% \ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\

We also have
\begin{eqnarray*}
\ket{\psi}&=&\ket{v_1 w_1}+\ket{v_2 w_2}\\
&=& (v_{11}\ket{e_1}+v_{21}\ket{e_2}+v_{31}\ket{e_3}) \otimes (w_{11}\ket{e_1}+w_{21}\ket{e_2}+w_{31}\ket{e_3}) \\
&+& (v_{12}\ket{e_1}+v_{22}\ket{e_2}+v_{32}\ket{e_3}) \otimes (w_{12}\ket{e_1}+w_{22}\ket{e_2}+w_{32}\ket{e_1}).
\end{eqnarray*}
Therefore,
\begin{equation}
M(\ket{\psi})=
\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} 
\end{pmatrix},
\end{equation}
so 
$$PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi}).$$
Thus, we have established that $rank(M(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=2$.
\end{example}


\textcolor{blue}{I changed this paragraph a bit.  I think it sounds better, but I'm not crazy about the Einstein stuff in the middle.}

Our task is to now show our this mathematical description of entanglement is consistent with the correlation that motivated the phrase "spooky action at a distance." In the 1930s Einstein was unhappy with the notion that an event at one point in the universe could influence another one far away.  We examine a {\emph{real world}} situation where entanglement occurs, for example, when a laser beam is fired through a special kind of crystal to form a pair of entangled photons. Once either one of the photons is measured (as introduced in \textbf{Section \ref{subsection:projective measurement}}), the state of the entire entangled system {\emph{collapses}}.  In particular, the state of the other photon collapses as well, {\emph{although it may be very far away from the place where the measurement occurs.}} To explain this, Einstein theorized that the two photons contained some information that was hidden from us until the moment of measurement. While this "hidden information" idea ultimately was proven wrong by John Bell (see \textbf{Section \ref{section: bell-nonlocality}}), the fact remains that entanglement allow for the {\emph{exchanging}} of information. In other words, even though Alice's photon may be at Smith College while Bob's is on Mars, Bob may be able to gain information about Alice's photon by measuring his. Next we will show that our "rank test" for entanglement can capture the correlation between the component states of composite system after measurement.

We now define the strength of entanglement of a composite system in terms of the coefficient matrix, and show that our notion is consistent with the degree to which the post measurement states in a composite system are correlated.
% If the rank being 1 implies the joint quantum state is not entangled, what if the coefficent matrix has full rank? We now may make the following definition and proceed to classify the strength of entanglement in terms of the rank of the coefficient matrix. Here by strength, we mean how much information Bob has about Alice once Alice measures on her part of the composite system.

\begin{definition} \label{def: maximally entangled}
 Let $\ket{\psi}$ be a state in ${\mathbb{C}}^{(n^2)}$.  Then, the entanglement degree of $\ket{\psi}$ is $rank(M(\ket{\psi}))$.  If the entanglement degree of $\ket{\psi}$ is $n$, we say $\ket{\psi}$ is maximally entangled \footnote{This is not the standard definition of maximal entanglement.  More commonly, a maximally entangled states are ones with maximum von Neumann entropy for each bipartition. This is equivalent to saying that the reduced density matrix $\rho_A, \rho_B$ are both a multiple of the identity matrix}.
\end{definition}


Note that $\ket{\psi}$ is entangled exactly when it's entanglement degree is greater than one.  We now describe the composite system analogue of the situation described in \textbf{Example \ref{example: orthogonal states for measurements}} and \textbf{Example \ref{example: non-orthogonal states for measurements}}, where Bob tries to determine which state Alice picks from a known basis. 

In this {\emph{quantum version}}, Alice and Bob share a composite state which is known to both parties.  This time, instead of Alice {\emph{selecting}} an element of a basis, she {\emph{measures}} her part of the composite state with respect to an orthonormal basis, which is known to Bob (see \textbf{Figure \ref{fig:entanglement}}).  Thus {\emph{Alice's state}} will be her end state post measurement, which is necessarily and element of the orthonormal basis.  Just like in the previous situation, the goal is for Bob to determine Alice's state with certainty.  A schematic is presented in \textbf{Figure \ref{fig:entanglement}}.


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{"entangled to alice and bob".png}
    \caption{Alice and Bob sharing an entangled state. Suppose that Alice measures with respect to an orthonormal basis $\{\varphi_i\}$ and obtains an end state $\ket{\varphi}$.  Then, the post measurement state for Bob after Alice's measurement is $\ket{\theta}$. That is, their composite system has end state $\ket{\varphi}\otimes\ket{\theta}$}
    \label{fig:entanglement}
\end{figure}
\textcolor{red}{add a tensor in between}


We will see that there are two requirements that must be met if Bob is to be able to carry out his task with certainty.
\begin{enumerate} 
    \item After Alice's measurement there must be a perfect correlation between Alice's end state $\ket{\varphi}$ and (the post measurement) state of Bob's system $\ket{\theta}$.  That is to say, {\emph{if one knows}} $\ket{\theta}$ and Alice and Bob's shared composite state, then one can recover $\ket{\varphi}$.
    \item Bob must be able to {\emph{access}} his state without creating additional uncertainty.
\end{enumerate}

We address the first requirement in this Section and the second requirement in next Section.  We wish to emphasize that initially {\emph{only Alice}} measures her part of their shared state with respect to an orthonormal basis.  Still, because of this measurement, the state of their composite system collapses.  


Suppose that Alice measures with respect to an orthonormal basis ${\{\ket{\varphi_i}\}}_{i=1}^{n}$.  Then, we know that for some $i_0$, she will observe outcome $i_0$, in which case her system will have $\ket{\varphi_{i_0}}$ as it's end state. Using density matrices, this corresponds to a situation \textcolor{green}{we do an operation }
% where Alice measures with respect to
$\ket{\varphi_{i_0}}\bra{\varphi_{i_0}} \otimes \mathbb{I}$ \textcolor{green}{on the composite system consisting of Alice and Bob}.  

In our next Proposition, we consider the situation where Alice's system yields state vector $\ket{\varphi}$ post measurement.  This corresponds to the case where Alice is measuring with respect to {\emph{any}} orthonormal basis that contains $\ket{\varphi}$ as an element. Our task is to determine how correlated Bob's and Alice's states are after she has measured.  


'\textcolor{blue}{We have to make sure enough is said about this version of the measurement computation.  I've changed some of them, but we can't call a state an "outcome".  Alice observes some outcome and the post measurement state is psi.  Also, in the Proofs below, make sure we don't use any notation or computations that we haven't defined or shown}
\textcolor{red}{outcome refers to the index instead of the actual state. check all of them.}

\textcolor{red}{add to the chapter in density matrix to justify our computation. change the prop to only use state}
\begin{prop}
\label{entanglement-rank}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a composite state shared by Alice and Bob. Say Alice first makes a measurement and observes an outcome with end state $\ket{\varphi}$. Let the state of Bob's system after Alice has performed the measurement be denoted by $\ket{\theta}$. Then,
\begin{enumerate}
    \item $rank(M(\ket{\psi}))=1$ if and only if $\ket{\theta}$ is constant.  That is, $\ket{\theta}$ is independent of $\ket{\varphi}$. In this situation, the state of Bob's system has no correlation with Alice's measurement end state.
    \item $rank(M(\ket{\psi}))=n$ if and only if the state of Bob's system has perfect correlation with Alice's measurement end state.
    \item $1<rank(M(\ket{\psi}))<n$, then the state of Bob's system has partial correlation with Alice's measurement end state.
\end{enumerate}
\end{prop}

This means that if the rank is $n$, that what is on Bob's side of the tensor product is perfectly correlated with what is on Alice's side.  If their states are not entangled, there is no correlation at all between their end states after Alice's measurement.  On the other hand, if their joint state is entangled, but not maximally, there is some (but not perfect) correlation.  

Much of the Proposition follows from the following Lemma.  



% We now consider the use of the shared state $|X\rangle$ in message transmission.  Our goal is to classify exactly to what extent information can be transmitted remotely between two parties by use of shared states. The following lemma will tell us what happens in this situation when one of Alice or Bob observes a state $|\psi\rangle$.

\begin{lemma}
\label{end state lemma}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a composite state shared by Alice and Bob.  Then,
\begin{enumerate}
\item Say Alice makes a measurement and observes $\ket{\varphi}$, then Bob's state is $\ket{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M(\ket{\psi})^T \cdot \overline{\ket{\varphi}}$, where $C$ is a constant.
\item Similarly, if Bob was to make a measurement and observes $\ket{\varphi}$, then Alice's state is $\ket{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M(\ket{\psi})^T\cdot \overline{\ket{\varphi}}$, where $C$ is a constant.\\

\end{enumerate}
\end{lemma}

Thus, when Alice's post measurement vector is $\ket{\varphi}$, Bob's is given by left multiplication by $M(\ket{\psi})^T$ up to a global phase and taking conjugates.

\begin{proof}
It is convenient to work with density matrices.  Thus, we first compute $\rho=\iota(\ket{\psi})\ket{\psi}\bra{\psi}$.  Let $\ket{\psi}$ be given by 
\begin{equation}
\ket{\psi}=\icol{a_1\\ \vdots \\a_{n^2}}.
\end{equation}
Then, 

\begin{equation}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}   
\end{equation}

Now say
\begin{equation}
\ket{\varphi}=\icol{b_1\\ \vdots \\b_n}.
\end{equation}
Say Alice observes $\ket{\varphi}\bra{\varphi}_A$.
Then the post measurement state conditioned on obtaining the outcome $\ket{\varphi}_A$ is
\begin{equation}
\rho_{\ket{\psi}_A}^{AB}=\frac{(\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB}(\ket{\varphi}\bra{\varphi}_A \otimes I_B)}{tr((\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB})}
\end{equation}

Let $C$ be the denominator of the above expression. Then 
\begin{eqnarray}
\rho_{\ket{\psi}_A}^{AB}&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\ket{\psi}\braket{\psi|e_i}\braket{e_{i'}|\psi}\bra{\psi}_A \otimes \ket{e_j}\bra{e_{j'}}_B\\
&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}_B\\
&=&\ket{\varphi}\bra{\varphi}_A \otimes \frac{1}{c} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}
\end{eqnarray}

So after Alice's measurement, Bob's state is
\begin{equation}
    \ket{\theta}\bra{\theta}=\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}} 
\end{equation}
This implies that 
\begin{equation}
    \ket{\theta}=\frac{1}{\sqrt{C}} M(\ket{\psi_i})^T \overline{\ket{\varphi}},
    \text{where } \overline{\ket{\varphi}}=\icol{\overline{b_1}\\ \vdots \\ \overline{b_n}}
\end{equation}


Similarly, say Bob observes $\ket{\varphi}\bra{\varphi}$. Then the post measurement state conditioned on Bob obtaining the outcome $\ket{\psi}_B$ is $$\rho_{\ket{\psi}_B}^{AB}=\frac{(I_A \otimes \ket{\psi}\bra{\psi}_B  )\rho_{AB}(I_A \otimes \ket{\psi}\bra{\psi}_B)}{tr((I_A \otimes \ket{\psi}\bra{\psi}_B)\rho_{AB})}$$.
Then Alice's post measurement state is $$\ket{\theta}=\frac{1}{\sqrt{C}} M(\ket{\psi_i})^T \overline{\ket{\varphi}}$$.

The result follows by {\bf{Lemma}} \ref{lemma state into density}.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{entanglement-rank}}.

\textcolor{blue}{The proof below should include a more explicit analysis of Bob trying to "invert" to find Alice's end state. In the case where the rank is m, we have a statement about which vectors can be solved for which shows that the correlation is partial, exactly when m is less than n.  Also, for final editing, this proof, as well as the proof above, should look a little better i.e. more spacing, more use of equation etc.  We should also get rid of implication arrows and write words instead.  First suppose...By the way, maybe there's almost nothing to write in the rank 1 if and only if constant part.  We already know when two vectors have the same overlay} \textcolor{green}{what do you mean by a more explicit analysis of Bob trying to "invert" to find Alice's end state?}
\textcolor{red}{use equations most of the time. no arrows except for in equation arrays.}


\textcolor{red}{**********DON'T EDIT THIS PROOF YET.  I HAVE AN IDEA FOR THIS***********}

\medskip

*****************************BEGIN*****************************


{\bf{Proposition}} \ref{entanglement-rank} follows from the following result.  Assume all the notation of {\bf{Proposition}} \ref{entanglement-rank}.
\begin{prop}
\label{correlation}
Suppose $rank({M(\ket{\psi})}^T)=m$, and let $j_1, j_2, ... j_m$ be the indices of the columns of the reduced row echelon form of $M(\ket{\psi}^T$ that have a leading one.  Suppose further that $\ket{\varphi} \in span\{\ket{e_{j_1}}, ... \ket{e_{j_m}}\}$.  Then if one knows $\ket{\theta}$, one can determine $\ket{\varphi}$ uniquely.  
\end{prop}
Thus, {\bf{Proposition}} \ref{correlation} says that if the $\ket{\psi}$ is maximally entangled,$\ket{\varphi}$ and $\ket{\theta}$ are perfectly correlated in the sense that from $\ket{\theta}$ one can {\emph{always}} uniquely determine $\ket{\varphi}$.  If $\ket{\psi}$ is entangled with entanglement degree $m<n$, then given $\ket{\theta}$ one can determine $\ket{\varphi}$ if we suppose first that $\ket{\varphi}$ lies in an $m$-dimensional subspace.  In this sense there is partial correlation between end states but not total.  Note that when $\ket{\psi}$ is separable, {\bf{Proposition}} \ref{correlation} tells us that $\ket{\theta}$ conveys no information about $\ket{\varphi}$.  This is clear, since up to a global phase there is a unique state in the direction of $\ket{e_j}$ for any $j$.

We now prove {\bf{Proposition}} \ref{correlation}.
\begin{proof}
As in the proof of {\bf{Lemma}} \ref{end state lemma}, we work with density matrices here.  From {\bf{Lemma}} \ref{end state lemma},
\begin{eqnarray}
\ket{\theta}\bra{\theta}&=&{M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot({M(\ket{\psi})}^T\overline{\ket{\varphi}})^\dagger\\
&=&{M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot {(\overline{\ket{\psi}})}^\dagger {({M(\ket{\psi})}^T)}^\dagger \\
&=&{M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot \overline{\bra{\varphi}} {({M(\ket{\psi})}^T)}^\dagger.
\end{eqnarray}
Now let $Y$ be the reduced row echelon form of $({M(\ket{\psi})}^T$ and let $A$ be the an $n$ by $n$ invertible matrix with
\begin{equation}
A \cdot ({M(\ket{\psi})}^T=Y.
\end{equation}
Then by our last computation,
\begin{eqnarray}
A\ket{\theta}\bra{\theta}A^\dagger&=&A {M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot \overline{\bra{\varphi}} {({M(\ket{\psi})}^T)}^\dagger A^\dagger\\
&=&Y \overline{\ket{\varphi}} \overline{\bra{\varphi}} Y^\dagger\\
&=& \ket{\tau}\bra{\tau},\textrm{ where }\ket{\tau}=Y\overline{\ket{\varphi}}.
\end{eqnarray}
Now, let 
\begin{equation}
\overline{\ket{\varphi}}=\icol{x_1 \\ \vdots \\ x_n} \textrm{ and }\ket{\tau}=\icol{z_1\\ \vdots \\ z_n}.
\end{equation}
Since $\ket{\varphi}$ is in the span of the the $\ket{e_{j_i}}$, $\overline{\ket{\varphi}}$ is as well.  Thus, since $Y$ is in reduced row echelon form, $x_{j_i}=z_i$.  But $\ket{\tau}$ is uniquely determined by {\bf{Lemma}} \ref{lemma state into density}.  Thus, by taking conjugates, we have determined $\ket{\varphi}$ uniquely as required.


\end{proof} 



**************************END*********************************
\begin{proof}
Let $$M(\ket{\psi})=
\begin{pmatrix}
\vert && \vert && \hdots && \vert\\
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
\vert && \vert && \hdots && \vert\\
\end{pmatrix}$$
Suppose $rank(M(\ket{\psi}))=m$.\\
Without loss of generality, let $\ket{v_{m+1}}, \ket{v_{m+2}},...,\ket{v_n} \in span(\ket{v_1},\ket{v_2},...,\ket{v_m})$, where $\ket{v_1}, ...\ket{v_m} $ are linearly independent.\\
Then there exist scalar sets 
\begin{gather}
\{\lambda_{(m+1),1}, \lambda_{(m+1),2},..., \lambda_{(m+1),m}\},\\
\{\lambda_{(m+2),1}, \lambda_{(m+2),2},..., \lambda_{(m+2),m}\},\\
\vdots\\
\{\lambda_{n,1}, \lambda_{n,2},..., \lambda_{n,m}\}    \end{gather}
 such that $\ket{v_{m+1}}=\sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i},...,\ket{v_n}=\sum_{i=1}^m \lambda_{n, i}\ket{v_i}$. Then

\begin{equation}
M(\ket{\psi})^T=\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}    
\end{equation}

When Alice observes $\ket{\psi}$, Bob is essentially trying to solve for the equation\\
\begin{equation}
\ket{\theta}= \frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\overline{\ket{\psi}}  
\end{equation}
Apparently, there are $n-m$ free variables in $\overline{\ket{\psi}}$. This implies that the second statement and the third statement in \textbf{Proposition \ref{entanglement-rank}} are correct.

\bigskip
Let's prove the first statement in \textbf{Proposition \ref{entanglement-rank}}.

$(\Rightarrow):$ When $m=1$, 
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\text{---} && \lambda_2\ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \lambda_n\ket{v_1}^T &&\text{---} \\
\end{pmatrix}
\overline{\ket{\psi}}\\
=\frac{1}{\sqrt{C}}\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}
\end{equation}

Notice $C=(1+\lambda_2^2+\hdots+\lambda_n^2)n(\braket{\psi|v_1})^2$. So\\
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}\braket{\psi|v_1}}
\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\frac{\lambda_2}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\vdots\\
\frac{\lambda_n}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}
\end{pmatrix} 
\end{equation}
which is a constant vector that does not depend on $\ket{\psi}$.

\bigskip
$(\Leftarrow):$ Suppose $\ket{\theta}\bra{\theta}$ is a constant matrix that doesn't depend on $\ket{\psi}$. This means for an arbitrary $\ket{\psi}$, the normalized $M(\ket{\psi})^T \overline{\ket{\psi}}$ should always be equal to $\ket{\theta}$.

For contradiction, assume $rank(M(\ket{\psi})) \ge 2$. Let $\ket{\psi}=\ket{e_1}$. Then
\begin{equation}
\ket{\theta} = \frac{1}{\sqrt{C_1}}
\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\ket{e_1}
=\frac{1}{\sqrt{C_1}}
\begin{pmatrix}
v_{11}\\
v_{12}\\
\vdots\\
v_{1m}\\
\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}    
\end{equation}

Let $\ket{\psi}=\ket{e_2}$. Then
$\ket{\theta}=
\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}$.

Repeat the process until $\ket{\psi}=\ket{e_n}$. Then we get\\
$\ket{\theta}
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}
=\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}
=\hdots
=\begin{pmatrix}
\frac{1}{\sqrt{C_n}}v_{n1}\\
\frac{1}{\sqrt{C_n}}v_{n2}\\
\vdots\\
\frac{1}{\sqrt{C_n}}v_{nm}\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{(m+1), i} v_{ni}\\
\vdots\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{n, i} v_{ni}
\end{pmatrix}$\\
So $v_{11}:v_{21}:\hdots:v_{n1}=v_{12}:v_{22}:\hdots:v_{n2}=\hdots=v_{1m}:v_{2m}:\hdots:v_{nm}$.\\
Therefore $\{\ket{v_1}, \ket{v_2},\hdots, \ket{v_m}\}$ is linearly dependent.\\
So $rank(M(\ket{\psi})) = 1$. Contradiction!\\
So when $\ket{\theta}$ is non-constant, the rank must be at least 2.\\
\end{proof}

\textcolor{red}{can be proved theoretically. No matter the $\ket{\varphi}$ Alice picked, the coefficient matrix will map it to the same unit vector up to a global phase (because we later prove $\ket{\varphi}$ cannot be in the kernel.}
We illustrate this correlation with some examples.
\textcolor{blue}{Actually, we probably need two examples here.  Make sure to use the same language when you describe each of them.  In these examples, we don't say anything about Bob measuring.  We only point out the correlation between Bob's side and Alice's side.  We can continue with the same examples in a subsequent section}

\begin{example}
\label{example rank full not orth}
Include example where the n=3=rank, but the matrix is not a scalar multiple of a unitary matrix.
\textcolor{red}{TODO. Only say there's perfect correlation. Say we will come back to this example in the next subsection.}
\end{example}

\textcolor{green}{Here is an example illustrating what it means for when we say "the state of Bob's system has partial correlation with Alice's measurement end state and only contains some information about Alice" as in \textbf{Proposition \ref{entanglement-rank}}, when the rank of the coefficient matrix is neither 1 or n.}
\begin{example}
\label{example rank not full}
Say Alice and Bob share a state $\ket{\psi}=\frac{1}{2\sqrt{2}}(\ket{e_1 e_1}+\ket{e_2 e_3}+\ket{e_3 e_1}+\ket{e_3 e_3}$).

Suppose Alice makes a measurement and yields $\ket{\varphi}=\icol{a\\b\\c}$, then from \textbf{Lemma \ref{end state lemma}}, Bob's post-measurement state is $\ket{\theta}$, where
\begin{equation} \label{eqn:example-theta}
\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
1 && 0 && 1\\
0 && 0 && 0\\
0 && 1 && 1\\
\end{pmatrix}\overline{\ket{\varphi}}=\frac{1}{\sqrt{C}}\begin{pmatrix}
\overline{a+c}\\
0\\
\overline{b+c}
\end{pmatrix} 
\end{equation}
\textcolor{green}{
 Say Alice measures with respect to an orthonormal basis that consists of
    \begin{gather}
    \ket{\varphi_1}=\ket{e_1}\\ \ket{\varphi_2}=\frac{1}{\sqrt{2}}(-\ket{e_2}+\ket{e_3})\\
    \ket{\varphi_3}=\frac{1}{\sqrt{2}}(-\ket{e_2}-\ket{e_3})
    \end{gather}
By \eqref{eqn:example-theta}, we get the mapping from Alice's measurement end state $\ket{\varphi_i}$ to post-measurement state for Bob $\ket{\theta_i}$:
    \begin{gather}
        \ket{\varphi_1} \mapsto \ket{\theta_1}=\ket{e_1}\\
        \ket{\varphi_2} \mapsto \ket{\theta_2}=\ket{e_1}\\
        \ket{\varphi_3} \mapsto \ket{\theta_3}=\frac{1}{\sqrt{5}}(-\ket{e_1}-2\ket{e_3})
    \end{gather}
}
\textcolor{green}{The above mappings show that Alice yielding $\ket{\varphi_1}$ and $\ket{\varphi_2}$ makes no difference to the post-measurement state on Bob's system, while Bob post-measurement state corresponding to $\ket{\varphi_3}$ is distinctive from the other two $\ket{\theta}_i$. This is what we mean by "partial correlation" between Alice's measurement end state and Bob's post-measurement state, that there \emph{exists} an orthonormal basis that contain at least two $\ket{\varphi}_i$ that get mapped to the same post-measurement state in Bob's system.}
\end{example} 
\textcolor{green}{Notice that the \textit{"collision"} of mapping for the above example does not happen for an arbitrary orthonormal basis.} For example, here's the mapping from Alice's measurement end state $\ket{\varphi_i}$ to Bob's post-measurement state $\ket{\theta_i}$ if Alice measures with respect to the standard basis:
\begin{gather}
    \ket{e_1} \mapsto \ket{e_1}\\
    \ket{e_2} \mapsto \ket{e_3}\\
    \ket{e_3} \mapsto \ket{e_1}+\ket{e_3}
\end{gather}
The mapping is one-to-one now! \textcolor{green}{This means that when the rank of the coefficient matrix is neither 1 or full rank, if Alice picks a \textit{"lucky"} orthonormal basis, then assuming Bob also knows that basis, there still exist a \textit{perfect} correlation between Alice's measurement end state and Bob's post-measurement state as if in the case for full rank. The distinction between this and the full rank case is that in the latter case, the correlation is \textit{perfect} regardless of the orthonormal basis that Alice measures on. Similarly, in the case when the rank of the coefficient matrix is 1, there is no correlation regardless of the orthonormal basis that Alice picks. So our way of using the rank of the coefficient matrix to quantify the strength of correlation between Alice and Bob is more about the \textit{"worst case"} scenario.}

% Of course, we can use Gram-Schmidt to construct an orthonormal basis for $\mathbb{C}^3$ that contains both $\ket{\varphi}$ and $\ket{\varphi'}$. 


%  What this means is that for a coefficient matrix whose rank is neither 1 or the full rank, there exists some orthonormal basis that Alice can choose to measure on such that Bob will not be able to infer Alice's measurement result even if he knows the basis Alice chooses. Alice yielding $\ket{\varphi}$ and $\ket{\varphi'}$ will make no difference to what Bob observes on his side at all!


\textcolor{red}{we are not measuring yet, but we can come back to this example in a later section. Here we are just talking about the correlation. "it might seem that there is a perfect correlation...yet Bob won't be able to make a measurement in this case".}




%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------


Next, we take care of "old business" by making sure that Bob's post-measurement state in \textbf{Lemma \ref{end state lemma}} is {\emph{legal}}.  The point is that a priori the conjugate of Alice's post-measurement state could be in the kernel of the transpose of the coefficient matrix $M(\ket{\psi})$. If this were the case, {\bf{Lemma}} \ref{end state lemma} tells us that the post-measurement state would be zero, which is in fact not a valid quantum state.  Thus, we now show that this occurs with probability zero.

% \textcolor{blue}{In this proof, change outcome to end state and make the structure of the proof explicit.  That is, any u whose conjugate is in the kernel of the transpose of the coefficient matrix corresponds to an outcome that has probability zero.  Also, you don't have transposes in this proof.}\textcolor{green}{done}

\begin{prop} \label{null space}
Say Alice and Bob share a two-qudit quantum state $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^n$. \textcolor{green}{Alice's end state after her measurement can never be $\ket{u}$, such that} $\ket{\Bar{u}} \in Nul(M(\ket{\psi})^T)$.
\end{prop}
\begin{proof}
The shared density matrix is 
\begin{gather*}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}.  
\end{gather*}

Consider an arbitrary n-dimensional qudit $\ket{u}=\sum_1^n b_i \ket{e_i}$. Then
\begin{equation} \label{eqn: null space eqn 1}
    \braket{u|e_i}=\overline{b_i}, \braket{e_i|u}=b_i
\end{equation}
\textcolor{green}{We want to show that if $\ket{u}$'s conjugate happens to be in the kernel of $M(\ket{\psi})^T$, the probability of Alice's measurement end state being $\ket{u}$ is 0. Now suppose}
$\ket{\Bar{u}} \in Nul(M(\ket{\psi})^T)$, we have \begin{equation} \label{eqn: null space eqn 2}
    \forall i, \sum_{j=1}^n a_{ij} \overline{b_i}=0
\end{equation}
\textcolor{red}{reference where the formula for calculating the probability comes from. add the formula into the density matrix section and have the games reference the formula as well. why can we calculate the probability as if Alice and Bob are measuring at the same time? }
\textcolor{blue}{explain why this formula is justified in a composite state}
\begin{eqnarray*}
p(\ket{uv})&=&\braket{u v | \rho |u v}\\
&=&\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\braket{u|e_i}\braket{e_{i'}|u}_A \otimes \braket{v|e_j}\braket{e_{j'}|v}_B\\
&=&\sum_i \sum_{i'} \sum_j \sum_{j'}  a_{ij} \overline{a_{i'j'}} \braket{u|e_i}\braket{e_{i'}|u}_A \otimes \braket{v|j}\braket{j'|v}_B\\
&=&(\sum_i \sum_j a_{ij} \overline{b_i})(\sum_{i'} \sum_{j'} \overline{a_{i'j'}} b_{i'})_A \otimes \braket{v|j}\braket{j'|v}_B   \; \; \;  (by \;  \eqref{eqn: null space eqn 1})\\ 
&=& 0 \; \; \; (by \; \eqref{eqn: null space eqn 2})
\end{eqnarray*}
Thus, \textcolor{green}{Alice's measurement end state can never has conjugate that is} in the kernel of $M(\ket{\psi})^T$.
\end{proof}

\textcolor{green}{We have described when there exists perfect correlation between Alice's measurement end state $\ket{\varphi}$ and Bob's post-measurement state $\ket{\theta}$, thereby completing the first step that allows Bob to infer Alice's measurement end state. However, if Bob is not able to do a measurement on his post-measurement state, having a "perfect" correlation with Alice is useless. We therefore move on to the second step in the next section, in which we examine to what extent Bob can figure out Alice's $\ket{\varphi}$ by \emph{measuring} on his post-measurement state $\ket{\theta}$.}
% we examine to what extent Bob can {\emph{use}} his end state to figure out what outcome Alice observed.


%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------
\pagebreak

\section{Entanglement and Measuring}
In the last section we analyzed the way in which Alice's and Bob's end states are correlated when one of them measures a shared composite state. We now continue with our analysis, focusing on when Bob has {\emph{access}} to his state vector without introducing additional uncertainty. 
% This situation is similar to that of \textbf{Examples \ref{example: orthogonal states for measurements}} and \textbf{\ref{example: non-orthogonal states for measurements}}, only now instead of Alice {\emph{selecting}} a state, now she {\emph{measures}} and observes an outcome with an end state.  Specifically, in our previous setup, Alice chooses a state from an orthonormal basis $\{\ket{\varphi_i}\}_{i=1}^n$ known to both herself and to Bob. She then gives the state to Bob, whose task is to identify the index of that state. Our task is different. Now, Alice and Bob share a known composite 2-qudit state $\ket{\psi}$ and Alice measures with respect to the orthonormal basis. 

By \textbf{Lemma \ref{end state lemma}}, if the transpose of the coefficient matrix $M(\ket{\psi_i})$ preserves orthogonality and has full rank, Bob can measure with respect to the basis $\{M(\ket{\psi_i})^T \overline{\ket{\psi_i}}\}_{i=1}^n$, which must be orthonormal. Thus, by measuring with respect to {\emph{this orthonormal basis}} he will be able to infer which outcome Alice observed by simply applying the inverse of the transpose of the coefficient matrix to the his end state, and then taking conjugates. This is very much the quantum analogue of {\bf{Example}} \ref{example: orthogonal states for measurements}.

On the other hand, if the transpose of the coefficient matrix does not preserve orthogonality, Bob cannot determine Alice's outcome with certainty {\emph{even if their shared state is maximally entangled}}.  Thus, perfect correlation between Alice's and Bob's end states is not enough to guarantee that he knows the results of her measurement.  Therefore, as pointed out previously, there are two different reasons why  Bob may fail to know the result of Alice's measurement.  The first is that their state may not be maximally entangled, so their end states are not perfectly correlated.  The second, is that even though their end states are perfectly correlated, uncertainty is introduced when Bob tries to {\emph{access}} his end state by measuring.  The latter situation is the quantum analogue of {\bf{Example}} \ref{example: non-orthogonal states for measurements}.  The next Proposition characterizes exactly when Bob is able to infer Alice's measurement end state with certainty.
% \textcolor{red}{I think I had that $\ket{\psi}$ must be maximally entangled in the below proposition. Is that not needed? }

\begin{prop} \label{prop: ultimate}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a composite state shared by Alice and Bob. Say Alice makes a measurement with respect to a basis known to both herself and Bob.  Then, Bob can determine Alice's outcome with certainty if and only if the transpose of the coefficient matrix preserves orthogonality.
\end{prop}

\begin{proof}
This result follows from the calculations in the proof of \textbf{Proposition \ref{entanglement-rank}}, and the fact that a nonzero matrix which preserves orthogonality must be of full rank and is therefore maximally entangled.  Thus after {\bf{Proposition}} \ref{orthogonality preserving character} the result is proven.
\end{proof}
The next Proposition characterizes matrices that preserve orthogonality.



\begin{prop} \label{orthogonality preserving character}
Let $M$ be a square matrix.  Then $M$ is a nonzero scalar multiple of a unitary matrix if and only if $M$ is not identically zero and preserves orthogonality.

\end{prop}

\textcolor{blue}{I changed the statement of the Proposition as we discussed.  Make sure the proof is structured in an appropriate way for the current version.}


\begin{proof}
First prove the second half of the Proposition by contraposition: any nonzero singular square matrix does not preserve orthogonality. In other words, for an arbitrary nonzero singular $n \times n$ matrix M, there exist $\ket{u}, \ket{v} \in \mathbb{C}^n$ such that $\braket{u|v}=0$ but $\braket{Mu|Mv} \ne 0$.

Let the dimension of $ker(M)$ be m, and let $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}\}$ be a basis of $ker(M)$. Extend that basis to $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}, \hdots, \ket{x_n}\}$. Let
\begin{gather*}
    \ket{u}=\ket{x_1}+\ket{x_n}\\
    \ket{v}=\ket{x_1}-\ket{x_n}
\end{gather*}

Then $\braket{u|v}=(\bra{x_1}+\bra{x_n})(\ket{x_1}-\ket{x_n})=\braket{x_1|x_1}+\braket{x_n|x_1}-\braket{x_1|x_n}-\braket{x_n|x_n}=1+0-0-1=0$.

Since $\ket{x_1} \in ker(M)$, we also have
\begin{gather*}
    \ket{Mu}=M\ket{x_1}+M\ket{x_n}=M\ket{x_n}\\
    \ket{Mv}=M\ket{x_1}-M\ket{x_n}=-M\ket{x_n}    
\end{gather*}

Since $\ket{x_n} \notin ker(M)$, we have $\ket{\sigma}=M\ket{x_n} \ne 0$. So $\braket{Mu|Mv}=-\braket{\sigma|\sigma} \ne 0$. There exist $\ket{u}, \ket{v}$ whose orthogonality is not preserved by the matrix M, so the second half of the Proposition is true.

\bigskip
Now let's prove the first half of the Proposition.

Consider an arbitrary square matrix M that is a scalar multiple of a unitary matrix. Say $M=\lambda U$, where $\lambda$ is a scalar and $U$ is a unitary matrix.
Then if $\braket{u|v}=0$, we have
$$\braket{M(\ket{\psi}u|M(\ket{\psi}v}=\braket{\lambda Uu|\lambda Uv}=\lambda^2 \braket{u|(U^\dagger U)v}=\lambda^2 \braket{u|v}=0.$$ So orthogonality is preserved.

\bigskip
Let's prove the other direction. Say $\braket{Mu|Mv}=0$ when $\braket{u|v}=0$. Since M is a nonzero matrix, by the second half of the Proposition we just prvoed, M must be a nonzero invertible square matrix. 

Fix an arbitrary $v \in \mathbb{C}^n, v \ne 0$.\\ Since M is a nonzero invertible matrix, $M^\dagger M v \ne 0$.

$\forall u \in \mathbb{C}^n$, if $\braket{u|v}=0$, then $\braket{Mu|Mv}=0$, so $\braket{u|M^\dagger Mv}=0$.

So $\forall u \in v^\perp, u \in (M^\dagger Mv)^\perp$. So $v^\perp \subseteq (M^\dagger Mv)^\perp$.

Since $v^\perp$ and $(M^\dagger Mv)^\perp$ both have dimension $n-1$, $v^\perp = (M^\dagger Mv)^\perp$.

So $\exists \lambda_v$ such that $\lambda_v v = M^\dagger M v$. We want to show that regardless of what v we pick initially, $\lambda_v$ stays the same. In other words, if we fix $v' \in \mathbb{C}^n, v' \ne 0, \lambda_{v'} v' = M^\dagger M v', \lambda_v = \lambda_{v'}$
\begin{gather*}
\braket{v|v'}-\braket{v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{M^\dagger M v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{v|M^\dagger M v'}=0\\
\Rightarrow \lambda_v \braket{v|v'}-\lambda_{v'} \braket{v|v'}=0\\
\Rightarrow (\lambda_v -\lambda_{v'}) \braket{v|v'}=0\\
\Rightarrow  \lambda_v = \lambda_{v'} if \braket{v|v'} \ne 0
\end{gather*}

If $\braket{v|v'}=0$, $\exists \ket{v''}$ such that $\braket{v|v''} \ne 0$ and $\braket{v'|v''} \ne 0$. Then $\lambda_v =\lambda_{v''}, \lambda_{v'}=\lambda_{v''}$. So $\lambda_v=\lambda_{v'}$ even when $\braket{v|v'}=0$.

So for an arbitrary $\ket{v} \in \mathbb{C}^n, \ket{v} \ne 0$, $\exists \lambda$ that's independent of $\ket{v}$ such that $M^\dagger M v = \lambda v$. So $M^\dagger M=\lambda \mathbb{I}_n\Rightarrow \frac{1}{\sqrt{\lambda}}M^\dagger \frac{1}{\sqrt{\lambda}} M=\mathbb{I}_n\Rightarrow M$ is a scalar multiple of a unitary matrix.
\end{proof}



\textcolor{green}{The coefficient matrix of any quantum state is a nonzero square matrix. By \textbf{Lemma \ref{end state lemma}} and \textbf{Proposition \ref{orthogonality preserving character}}, we learn that after Alice has made her measurement with respect to an orthonormal basis ${\ket{\varphi}_i}_{i=1}^n$and yields an outcome $\ket{\varphi}$, Bob will only be able to actually measure with respect to an orthonormal basis $M(\ket{\psi})^T {\ket{\varphi}_i}_{i=1}^n$ if the transpose of the coefficient matrix $M(\ket{\psi})^T$ is a scalar multiple of a unitary matrix. For example, if Alice measured her part of the shared pair of entangled particles with respect to a basis $\{\ket{u}, \ket{v}\}$, then }
Bob can measure his part with respect to the basis $\{M(\ket{\psi})^T\ket{u}, M(\ket{\psi})^T\ket{v}\}$. When $M(\ket{\psi})^T$ is a scalar multiple of a unitary matrix, it is also invertible and hence has full rank. \textcolor{green}{Therefore, the initial 2-qudit state that Alice and Bob shared $\ket{\psi}$ is maximally entangled, implying that the state of Bob's system contains perfect information about Alice according to \textbf{Proposition \ref{entanglement-rank}}. Therefore, by measuring his system with respect to $\{M(\ket{\psi})^T\ket{u}, M(\ket{\psi})^T\ket{v}\}$, Bob can infer Alice's outcome that is either $\ket{u}$, or $\ket{v}$ by applying \textbf{Lemma \ref{end state lemma}}}. 
% Therefore, Bob can infer Alice's measured outcome once he knows which specific basis Alice picked.

Otherwise, Bob can only measure with respect to some basis $\{M(\ket{\psi})^T\ket{u}, (M(\ket{\psi})^T\ket{u})^\perp \}$ and can only infer something meaningful of Alice within certain probability.

\begin{example}
Consider a two-qubit joint state to be $\ket{\psi}=\frac{1}{\sqrt{2}}(\ket{00}+\ket{11})$. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$.

\textcolor{green}{$M(\ket{\psi})=\frac{1}{\sqrt{2}}\mathbb{I}$, so $M(\ket{\psi})^T=M(\ket{\psi})$, which is obviously a scalar multiple of the unitary matrix $\mathbb{I}$. So by \textbf{Proposition \ref{orthogonality preserving character}} and \textbf{Proposition \ref{prop: ultimate}}, we know Bob can determine Alice's measurement outcome with certainty. This is because he can measure with respect to  $\{M(\ket{\psi})^T\ket{0}, M(\ket{\psi})^T\ket{1}\}=\{\ket{1}, \ket{0}\}$. By Lemma \ref{end state lemma}, after Alice's measurement and Bob's measurement on their own system both with respect to the standard basis, if Bob observes the outcome $\ket{1}$ on his system, he can infer with certainty that Alice observes $\ket{0}$. If he observes the outcome $\ket{1}$ instead, he can infer that Alice observes $\ket{1}$.}
\end{example}

\textcolor{green}{Let's call all 2-qudit quantum states that allow Bob to determine Alice's measurement outcome with certainty \emph{"good"} states. More explicitly, the transpose of the coefficient matrix of a \emph{"good"} must have full rank and is a scalar multiple of a unitary matrix. For a 2-qudit states in $\mathbb{C}^2 \otimes \mathbb{C}^2$, there is an elegant characterization of all such \emph{"good"} states.} 
\begin{corollary}
$\ket{\psi}=\frac{1}{\sqrt{2}}(a\ket{00}+(-e^{i\theta})\Bar{b}\ket{01}+b\ket{10}+e^{i\theta}\Bar{a}\ket{11})$, where $|a|^2+|b|^2=1$ is a characterization of all good" states in $\mathbb{C}^2 \otimes \mathbb{C}^2$ such that if $\braket{u|v}=0$, then $\braket{M(\ket{\psi})^Tu|M(\ket{\psi})^Tv)}=0$.
\end{corollary}

\begin{example}
Consider a two-qubit state not within the characterization in Proposition \ref{orthogonality preserving character} $\ket{\psi}=\frac{1}{\sqrt{3}}(\ket{00}+\ket{01}+\ket{10})$. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$.

Bob will not be able to measure on $\{M(\ket{\psi})\ket{0}, M(\ket{\psi})\ket{1}\}=\{\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}}
\end{pmatrix},\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
0
\end{pmatrix}\}$ because it's not orthogonal. So he will only be able to choose to measure on $\{M(\ket{\psi})\ket{0}, (M(\ket{\psi})\ket{0})^\perp \}$ or $\{(M(\ket{\psi})\ket{1})^\perp, M(\ket{\psi})\ket{1} \}$.
Without loss of generality, let's say Bob chooses to measure on $\{M(\ket{\psi})\ket{0}, (M(\ket{\psi})\ket{0})^\perp \}=\{\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}}
\end{pmatrix}, \begin{pmatrix}
\frac{1}{\sqrt{3}}\\
-\frac{1}{\sqrt{3}}
\end{pmatrix}\}$.
We normalize the two vectors and call them $\ket{u}'$ and $\ket{v}'$, respectively. So the orthonormal basis for Bob is $\{\ket{u'}, \ket{v'}\}$, where $\ket{u}'=\begin{pmatrix}
\frac{1}{\sqrt{2}}\\
\frac{1}{\sqrt{2}}
\end{pmatrix}$, $\ket{v}'=\begin{pmatrix}
\frac{1}{\sqrt{2}}\\
-\frac{1}{\sqrt{2}}
\end{pmatrix}$. Therefore to Bob, if he measures with basis $\ket{u'}, \ket{v'}$ and yields $\ket{v'}$, he can infer with certainty that Alice observes $\ket{1}$. However, if Bob yields $\ket{u'}$, then he is not able to tell what Alice observes.
\end{example}
%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------
\pagebreak

\textcolor{blue}{Need to add some here.  Also maybe add a diagram or a series of diagram} \textcolor{green}{what kind of diagram?}
\textcolor{red}{use Alice and Bob diagrams}
\section{Application to a One-time Pad}
The above classification of entanglement can potentially be used in the following cryptographic scheme.
\begin{enumerate}
    \item Bob creates a series of maximally entangled (as defined in \textbf{Definition \ref{def: maximally entangled}}) 2-qudit states $L={\ket{\psi_1}, \ket{\psi_2}, \hdots, \ket{\psi_m}}$, where $\ket{\psi_i} \in \mathbb{C}^n \otimes \mathbb{C}^n$. He sends the left qudit of each state to Alice via a quantum communication channel and keep the right side to himself.
    \item Via a classical communication channel that doesn't have to be secure, Alice notify Bob in order the set of orthonormal bases that she is going to make measurements with. In other words, for each $\ket{\psi_i}$, Alice randomly chooses an orthonormal basis $B_i=\{\ket{b_1}, \ket{b_2}, \hdots, \ket{b_n}\}$ and sends the elements in the basis in order to Bob.
    \item For each qudit received from L, Alice makes a measurement and saves her result locally. With the knowledge of L and $B_1, B_2, \hdots, B_m$, Bob will be able to infer Alice's measurement result by measuring with respect to basis $\{M(\ket{\psi_i})^T \ket{b_1}, M(\ket{\psi_i})^T \ket{b_2}, \hdots, M(\ket{\psi_i})^T \ket{b_n}\}$. He saves the result for each $\ket{\psi_i}$ and in the end get an m-digit long key that can be used for one-time pad introduced in \textbf{Definition \ref{def: quantum one-time pad}}.
\end{enumerate}
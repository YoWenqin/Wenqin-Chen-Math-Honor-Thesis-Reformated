% Chapter Template

\chapter{Classification of Entanglement} % Main chapter title

\label{Chapter6-classification of entanglement} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{"actual entanglement".jpg}
    \caption{The First-Ever Photo of Quantum Entanglement captured by physicists at the University of Glasgow. \cite{moreau2019imaging}}
    \label{fig:BB84 bit encoding}
\end{figure}

Entanglement is such a fascinating phenomenon in quantum mechanics that Albert Einstein described it as "spooky action at a distance". Quantum entanglement occurs when two particles become linked in way as if there's an invisible tunnel between them, and whatever happens to one immediately affects the other, regardless of how far apart they are. We briefly introduced entanglement in \textbf{Section \ref{section: composite systems}}. It is also used in the E91 Protocol laid out in \textbf{Section \ref{section: e91}}. A natural question that arises is how to classify entanglement for general 2-party composite systems in $\mathbb{C}^n \otimes \mathbb{C}^n$? Is there a notion of quantifying entanglement, i.e. the strength of the link between two particles?

% In quantum mechanics one envisions Alice and Bob {\emph{sharing}} a potential entangled state.  When this happens we think of Alice's {\emph{part}} of the shared state as being the part on the {\emph{left-hand side}} of the tensor product, while Bob has the {\emph{right-hand side}}.  Note that we do not assume that the shared state is separable.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{"alice bob entanglement".png}
    \caption{Alice and Bob sharing an entangled state}
    \label{fig:entanglement}
\end{figure}

In this chapter we will talk about Alice and Bob sharing arbitrary 2-qudit quantum state in $\mathbb{C}^n \otimes \mathbb{C}^n$. Call the standard basis in $\mathbb{C}^n$ S. The convention is to think of the \textit{left} qudit of the 2-qudit quantum state as representing Alice's component system or particle, and the \textit{right} qudit of the shared 2-qudit state to be of Bob's. We can write $\ket{\psi}$ in terms of $S \otimes S$ and denote the coeffcients with a certain coefficient matrix. The next proposition serves to answer whether the rank of that coefficient matrix can be a well-defined tool to test if the state $\ket{\psi}$ is entangled and even further quantify the strength of entanglement.

\begin{prop}
\label{rank prop}
Let $\ket{\psi}$ be a state in $\mathbb{C}^n \otimes \mathbb{C}^n$, and let $S=\{\ket{e_i}\}$ be the standard basis for $\mathbb{C}^n$. Let the coefficient matrix $M_{S \otimes S}(\ket{\psi})=(a_{i,j})$, where $\ket{\psi}=\sum\limits_{i,j}a_{i,j}|e_i e_j\rangle$.  Define $S(\ket{\psi})=\{m\in \mathbb{N}: \ket{\psi}=\sum_{i=1}^m\ket{v_i w_i}, for \ket{v_i}, \ket{w_i} \in \mathbb{C}^n\}$.  Then, $rank(M_{S \otimes S}(\ket{\psi}))=\textrm{min} (S(\ket{\psi})$.
% Thus in particular, the state $\ket{\psi}$ is a tensor product (not entangled) if and only if the matrix $M_{\ket{\psi}}$ is singular with rank one.
\end{prop}
This proposition shows that even though we can write $\ket{\psi}$ in different bases, the rank of the coefficient matrix associated with the standard basis is the smallest among all other coefficient matrices associated with other bases. To prove the proposition, we first prove the following lemma.

\begin{lemma}
\label{independence lemma}
Let $k=min S(\ket{\psi})$, and suppose $\ket{\psi}=\sum\limits_{i=0}^k \ket{v_iw_i}$.  Then $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ must both be linearly independent.
\end{lemma}

\begin{proof}
For a contradiction, let $k, \ket{\psi}, \ket{v_i}, \ket{w_i}$ be as above, and suppose that $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ is linearly dependent. Then without the loss of generality, say $\ket{v_k} \in span\{\ket{v_1}, \ket{v_2},...\ket{v_{k-1}}\}$. Then, $\ket{v_k}=\sum_i^{k-1} a_i \ket{v_i}$, for constants $a_i \in \mathbb{C}$.  Then, 
\begin{eqnarray*}
\ket{\psi}&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \ket{v_k w_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \sum_{i=1}^{k-1} a_i\ket{v_iw_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i} \otimes (\ket{w_i}+a_i\ket{w_k}).\\
\end{eqnarray*}

Apparently, $(k-1) \in S(\ket{\psi})$, contradicting the minimality of $k$.  Thus, $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_m}\}$ are linearly independent.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{rank prop}}.

\begin{proof}
Say $k=min(S(\ket{\psi}))$. Then, $\ket{\psi}=\sum_{i=1}^k \ket{v_i w_i}$, where $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ are linearly independent by Lemma \ref{independence lemma}.  Thus, we can extend each linearly independent set to bases for $\mathbb{C}^n$. Thus, let $B=\{\ket{v_1}, \ket{v_2},...,\ket{v_k}, \ket{v_{k+1}},...,\ket{v_n}\}$ and $B'=\{\ket{w_1}, \ket{w_2},...,\ket{w_n}\}$ be bases, and let $M_{B \otimes B'}(\ket{\psi})$ denote the coefficient matrix of $\ket{\psi}=\sum_{i=1}^{n}\ket{v_i w_i}$ with respect to the basis $B \otimes B'$. By inspection, 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_k && 0 \\
0 && 0
\end{pmatrix}$$
so $rank(M_{B \otimes B'}(\ket{\psi}))$ is k.

Thus, to show $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M_{S \otimes S}(\ket{\psi})$, we will find two invertible $n \times n$ matrices P, Q with $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$.

To do this, say $\ket{v_i}=\sum_{j=1}^n v_{ji}\ket{e_j}$, and
$\ket{w_i}=\sum_{j=1}^n w_{ji}\ket{e_j}$.  Since B and B' are both linearly independent, $P=(v_{i,j})$ and $Q=(w_{i,j})$ are both invertible.
% $P=\begin{pmatrix}
% \vert && \vert && \hdots && \vert\\
% \ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
% \vert && \vert && \hdots && \vert\\
% \end{pmatrix}$,\\
% $Q^{-1}=\begin{pmatrix}
% \text{---} && \ket{w_1}^T &&\text{---} \\
% \text{---} && \ket{w_2}^T &&\text{---} \\
% \vdots && \vdots && \vdots \\
% \text{---} && \ket{w_n}^T &&\text{---} \\
% \end{pmatrix}$.


Then, set $(b_{i,j})=PM_{B \otimes B'}(\ket{\psi})Q^{-1}$.  By direct computation, we have that
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

=\begin{pmatrix}
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}
\end{pmatrix}
\begin{pmatrix}
\text{---} && \ket{w_1}^T &&\text{---} \\
\text{---} && \ket{w_2}^T &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \ket{w_k}^T &&\text{---} \\
\text{---} && 0 &&\text{---}
\end{pmatrix}\\
=\begin{pmatrix}
v_{11}w_{11}+\hdots+v_{1k}w_{1k} && v_{11}w_{21}+\hdots+v_{1k}w_{2k} && \hdots && v_{11}w_{n1}+\hdots+v_{1k}w_{nk}\\
v_{21}w_{11}+\hdots+v_{2k}w_{1k} && v_{21}w_{21}+\hdots+v_{2k}w_{2k} && \hdots && v_{21}w_{n1}+\hdots+v_{2k}w_{nk}\\
\vdots && \vdots && \vdots && \vdots\\
v_{n1}w_{11}+\hdots+v_{nk}w_{1k} && v_{n1}w_{21}+\hdots+v_{nk}w_{2k} && \hdots && v_{n1}w_{n1}+\hdots+v_{nk}w_{nk}
\end{pmatrix}

\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{gather*}
    b_{ij}=\sum_{t=1}^k v_{it}w_{jt}
\end{gather*}


On the other hand,
\begin{eqnarray*}
\ket{\psi}&=&\sum_{i=1}^k \ket{v_i w_i}\\
&=&\sum_{i=1}^k \left(\sum_{j=1}^{n} v_{ji} \ket{e_j}) \otimes (\sum_{s=1}^n w_{si}\ket{e_s}\right)\\
&=&\sum_{i=1}^k \sum_{j=1}^{n} \sum_{s=1}^n v_{ji} w_{si} \ket{e_j e_s}\\
\end{eqnarray*}

\noindent
Thus, if $M_{S \otimes S}(\ket{\psi})=(a_{lr})$, then $a_{lr}=\sum_{i=1}^k v_{lk} w_{rk}=b_{lr}$.
So $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$.  Therefore, $rank(M_{S \otimes S}(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=k$.
\end{proof}

The computation above looks a bit complicated. You can verify it with the following example, the case when k=2, n=3.
\begin{example}
Consider the case where $k=2, n=3$.

Then 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_2 && 0 \\
0 && 0
\end{pmatrix}$$.

We want to show $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M_{S \otimes S}(\ket{\psi})=2$ by finding two $3\  \times 3$ invertible matrices P,Q such that $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$.
Let
\begin{gather*}
\ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
\ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\
P=(\ket{v_1}, \ket{v_2}, \ket{v_3})\\
Q^{-1}=(\ket{w_1}, \ket{w_2}, \ket{w_3})^T
\end{gather*}

Then
\begin{eqnarray*}
P M_{B \otimes B'}(\ket{\psi}) Q^{-1}&=&\begin{pmatrix}
v_{11} && v_{12} && v_{13}\\
v_{21} && v_{22} && v_{23}\\
v_{31} && v_{32} && v_{33}
\end{pmatrix}
\begin{pmatrix}
1 && 0 && 0\\
0 && 1 && 0\\
0 && 0 && 0\\
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11} && v_{12} && 0\\
v_{21} && v_{22} && 0\\
v_{31} && v_{32} && 0
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} \\
\end{pmatrix}
\end{eqnarray*}


% \ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
% \ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\

We also have
\begin{eqnarray*}
\ket{\psi}&=&\ket{v_1 w_1}+\ket{v_2 w_2}\\
&=& (v_{11}\ket{e_1}+v_{21}\ket{e_2}+v_{31}\ket{e_3}) \otimes (w_{11}\ket{e_1}+w_{21}\ket{e_2}+w_{31}\ket{e_3}) \\
&+& (v_{12}\ket{e_1}+v_{22}\ket{e_2}+v_{32}\ket{e_3}) \otimes (w_{12}\ket{e_1}+w_{22}\ket{e_2}+w_{32}\ket{e_1})\\
&=&\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} 
\end{pmatrix}
\end{eqnarray*}
So $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$ and $rank(M_{S \otimes S}(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=2$.
\end{example}

\bigskip
If the rank of the coefficient matrix associated with the standard basis is 1, it follows from the \textbf{Proposition \ref{rank prop}} this corollary:

\begin{corollary}
If $rank(M(\ket{\psi}))=1$, then the state $\ket{\psi}$ is separable. Otherwise, $\ket{\psi}$ is entangled.
\end{corollary}

If the rank being 1 implies the joint quantum state is not entangled, what if the coefficent matrix has full rank? We now may make the following definition.
\begin{definition}
 Let $\ket{\psi}$ be  a state in ${\mathbb{C}}^{(n^2)}$.  Then, the entanglement degree of $\ket{\psi}$ is $rank(M_{S \otimes S}(\ket{\psi}))$.  If the entanglement degree of $\ket{\psi}$ is $n$, we say $\ket{\psi}$ is maximally entangled.
\end{definition}

\textcolor{red}{conventional definition of maximally entangled: when we trace over the state B then the reduced density operator $\rho_A$ of the system will be a multiple of the identity operator. This means that if we measure in system A in any basis the result will be completely random (0 or 1 with equal probability 1/2)}.


When Alice and Bob share a state, Alice may measure her piece of the state, and if it is entangled, her measurement necessarily affects Bob's piece.

\begin{prop}
\label{entanglement-rank}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a 2-qudit quantum state shared by Alice and Bob. Say Alice first makes a measurement and observes $\ket{\varphi}$. Then Bob picks a basis that might not be the same as Alice's and observes $\ket{\theta}$ as a result. Then the following statements hold.
\begin{enumerate}
    \item $rank(M(\ket{\psi}))=1$ if and only if $\ket{\theta}\bra{\theta}$ is a constant matrix that doesn't depend on $\ket{\varphi}$. This means that Bob can obtain no information about Alice.
    \item $rank(M(\ket{\psi}))=n$ if and only if $\ket{\psi}$ is maximally entangled. This means that Bob can infer exactly the state Alice measured ($\ket{\varphi}$).
    \item If $1<rank(M(\ket{\psi}))<n$, Bob can only partially infer information about Alice.
\end{enumerate}
\end{prop}

First, let's prove the following lemma.



% We now consider the use of the shared state $|X\rangle$ in message transmission.  Our goal is to classify exactly to what extent information can be transmitted remotely between two parties by use of shared states. The following lemma will tell us what happens in this situation when one of Alice or Bob observes a state $|\psi\rangle$.

\begin{lemma}
\label{end state lemma}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a quantum state representing a composite system of Alice and Bob.  The shared density matrix is therefore $\rho = \ket{\psi}\bra{\psi}$. Then,
\begin{enumerate}
\item Say Alice makes a measurement and observes $\ket{\varphi}\bra{\varphi}$, then Bob's post-measurement state is $\ket{\theta}\bra{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M_{\ket{\psi}}^T \overline{\ket{\varphi}}$.
\item Say Bob makes a measurement and observes observes $\ket{\varphi}\bra{\varphi}$, then Alice's post-measurement state is $\ket{\theta}\bra{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M_{\ket{\psi}}^T \overline{\ket{\varphi}}$.\\
C is just a scalar.
\end{enumerate}
\end{lemma}

\begin{proof}
First compute the shared density matrix in terms of the standard matrix.
\begin{equation}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}   
\end{equation}

Let $\ket{\varphi}=\icol{b_1\\ \vdots \\b_n}$.

Say Alice observes $\ket{\varphi}\bra{\varphi}_A$.
Then the post-measurement state conditioned on obtaining the outcome $\ket{\varphi}_A$ is
\begin{equation}
\rho_{\ket{\psi}_A}^{AB}=\frac{(\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB}(\ket{\varphi}\bra{\varphi}_A \otimes I_B)}{tr((\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB})}
\end{equation}

The denominator is just a scalar. Call it C. Then 
\begin{eqnarray}
\rho_{\ket{\psi}_A}^{AB}&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\ket{\psi}\braket{\psi|e_i}\braket{e_{i'}|\psi}\bra{\psi}_A \otimes \ket{e_j}\bra{e_{j'}}_B\\
&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}_B\\
&=&\ket{\varphi}\bra{\varphi}_A \otimes \frac{1}{c} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}
\end{eqnarray}

So the post-measurement state for Bob is
\begin{equation}
    \ket{\theta}\bra{\theta}=\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}} \\ \Rightarrow \ket{\theta}=\frac{1}{\sqrt{C}} M_{\ket{\psi}}^T \overline{\ket{\varphi}},
    \text{where } \overline{\ket{\varphi}}=\icol{\overline{b_1}\\ \vdots \\ \overline{b_n}}
\end{equation}
% Now let's compute C:
% \begin{align}
% tr((\ket{\psi}\bra{\psi}_A \otimes I_B)\rho_{AB})
% &=tr((\ket{\psi}\bra{\psi}_A \otimes I_B)(\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}_A \otimes \bra{e_{i'} e_{j'}}_B))\\
% &=\sum_{i,j} \sum_{i',j'} a_{ij}  \overline{a_{i'j'}}tr(\ket{\psi}\braket{\psi|e_i}\bra{e_{i'}})tr(\ket{e_j}\bra{e_{j'}})\\
% &=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}tr(\braket{e_{i'}|\psi}\braket{\psi|e_i})tr(\braket{e_{j'}|e_j})\\
% &=\sum_j \sum_i \sum_{i'} a_{ij} \overline{a_{i'j}}\overline{b_i}b_{i'}\\
% &=|\ket{\theta}|^2
% \end{align}
% The above computation makes use of the property that the trace of the tensor product of two matrices is just the product of the trace of each matrix. i.e. $tr(A \otimes B)=tr(A) \times tr(B)$. That trace is computable has also been used. C apparently just normalizes $\ket{\theta}$. In other words,
% \begin{equation}
%     \ket{\theta}=\frac{1}{\sqrt{C}} M_{\ket{\psi}}^T \overline{\ket{\varphi}}=\frac{M_{\ket{\psi}}^T \overline{\ket{\varphi}}}{|\ket{\theta}|}
%     \Rightarrow \frac{\ket{\theta}}{|\ket{\theta}|}=M_{\ket{\psi}}^T \overline{\ket{\varphi}}
% \end{equation}

% $tr((\ket{\psi}\bra{\psi}_A \otimes I_B)\rho_{AB})\\
% =tr((\ket{\psi}\bra{\psi}_A \otimes I_B)(\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}_A \otimes \bra{e_{i'} e_{j'}}_B))\\
% =\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}tr(\ket{\psi}\braket{\psi|e_i}\bra{e_{i'}})tr(\ket{e_j}\bra{e_{j'}})  $ 
% (by Proposition \ref{trace of tensor product})\\
% $=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}tr(\braket{e_{i'}|\psi}\braket{\psi|e_i})tr(\braket{e_{j'}|e_j})$ (since trace is commutable)\\
% $=\sum_j \sum_i \sum_{i'} a_{ij} \overline{a_{i'j}}\overline{b_i}b_{i'}$ (since $\braket{e_{j'}|e_j}=0$ when $j' \ne j$)\\
% $=|\ket{\theta}|^2$.

Similarly, say Bob observes $\ket{\varphi}\bra{\varphi}$. Then the post-measurement state conditioned on Bob obtaining the outcome $\ket{\psi}_B$ is $\rho_{\ket{\psi}_B}^{AB}=\frac{(I_A \otimes \ket{\psi}\bra{\psi}_B  )\rho_{AB}(I_A \otimes \ket{\psi}\bra{\psi}_B)}{tr((I_A \otimes \ket{\psi}\bra{\psi}_B)\rho_{AB})}$.
Then Alice's post-measurement state is $\ket{\theta}=\frac{1}{\sqrt{C}} M_{\ket{\psi}}^T \overline{\ket{\varphi}}$.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{entanglement-rank}}.
\begin{proof}
Let $M(\ket{\psi})=
\begin{pmatrix}
\vert && \vert && \hdots && \vert\\
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
\vert && \vert && \hdots && \vert\\
\end{pmatrix}$\\
Suppose $rank(M(\ket{\psi}))=m$. Without loss of generality, let $\ket{v_{m+1}}, \ket{v_{m+2}},...,\ket{v_n} \in span(\ket{v_1},\ket{v_2},...,\ket{v_m})$.\\
Then there exist scalar sets $\{\lambda_{(m+1),1}, \lambda_{(m+1),2},..., \lambda_{(m+1),m}\}, \{\lambda_{(m+2),1}, \lambda_{(m+2),2},..., \lambda_{(m+2),m}\},...,\\
\{\lambda_{n,1}, \lambda_{n,2},..., \lambda_{n,m}\}$ such that $\ket{v_{m+1}}=\sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i},...,\ket{v_n}=\sum_{i=1}^m \lambda_{n, i}\ket{v_i}$. Then

\begin{equation}
M(\ket{\psi})^T=\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}    
\end{equation}

When Alice observes $\ket{\psi}$, Bob is essentially trying to solve for the equation\\
\begin{equation}
\ket{\theta}= \frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\overline{\ket{\psi}}  
\end{equation}
Apparently, there are (n-m) free variables in $\overline{\ket{\psi}}$. This implies that the second statement and the third statement in \textbf{Proposition \ref{entanglement-rank}} are correct.

\bigskip
Let's prove the first statement in \textbf{Proposition \ref{entanglement-rank}}.

$(\Rightarrow):$ When $m=1$, 
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\text{---} && \lambda_2\ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \lambda_n\ket{v_1}^T &&\text{---} \\
\end{pmatrix}
\overline{\ket{\psi}}\\
=\frac{1}{\sqrt{C}}\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}
\end{equation}

Notice $C=(1+\lambda_2^2+\hdots+\lambda_n^2)n(\braket{\psi|v_1})^2$. So\\
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}\braket{\psi|v_1}}
\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\frac{\lambda_2}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\vdots\\
\frac{\lambda_n}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}
\end{pmatrix} 
\end{equation}
which is a constant vector that does not depend on $\ket{\psi}$.

\bigskip
$(\Leftarrow):$ Suppose $\ket{\theta}\bra{\theta}$ is a constant matrix that doesn't depend on $\ket{\psi}$. This means for an arbitrary $\ket{\psi}$, the normalized $M(\ket{\psi})^T \overline{\ket{\psi}}$ should always be equal to $\ket{\theta}$.

For contradiction, assume $rank(M(\ket{\psi})) \ge 2$. Let $\ket{\psi}=\ket{e_1}$. Then
\begin{equation}
\ket{\theta} = \frac{1}{\sqrt{C_1}}
\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\ket{e_1}
=\frac{1}{\sqrt{C_1}}
\begin{pmatrix}
v_{11}\\
v_{12}\\
\vdots\\
v_{1m}\\
\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}    
\end{equation}

Let $\ket{\psi}=\ket{e_2}$. Then
$\ket{\theta}=
\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}$.

Repeat the process until $\ket{\psi}=\ket{e_n}$. Then we get\\
$\ket{\theta}
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}
=\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}
=\hdots
=\begin{pmatrix}
\frac{1}{\sqrt{C_n}}v_{n1}\\
\frac{1}{\sqrt{C_n}}v_{n2}\\
\vdots\\
\frac{1}{\sqrt{C_n}}v_{nm}\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{(m+1), i} v_{ni}\\
\vdots\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{n, i} v_{ni}
\end{pmatrix}$\\
So $v_{11}:v_{21}:\hdots:v_{n1}=v_{12}:v_{22}:\hdots:v_{n2}=\hdots=v_{1m}:v_{2m}:\hdots:v_{nm}$.\\
Therefore $\{\ket{v_1}, \ket{v_2},\hdots, \ket{v_m}\}$ is linearly dependent.\\
So $rank(M(\ket{\psi})) = 1$. Contradiction!\\
So when $\ket{\theta}$ is a constant, the rank must be at least 2.\\
\end{proof}

\begin{example}
\textcolor{red}{include example for computing bob's end state after alice makes her measurement in $C^3$. what will happen probabilistically for bob after alice makes her measurement?}
Say Alice and Bob share a state $\ket{\psi}=\frac{1}{2\sqrt{2}}(\ket{e_1 e_1}+\ket{e_2 e_3}+\ket{e_3 e_1}+\ket{e_3 e_3}$). Then Alice makes a measurement and yields $\ket{\varphi}$. 

Then from \textbf{Lemma \ref{end state lemma}}, Bob's post-measurement state is $\ket{\theta}\bra{\theta}$, $\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
1 && 0 && 1\\
0 && 0 && 0\\
0 && 1 && 1\\
\end{pmatrix}\overline{\ket{\varphi}}$
\end{example}

\bigskip
Now we know how Alice and Bob are correlated mathematically during the "spooky action at a distance". However, there seems to be loophole. What if the coefficient matrix $M(\ket{\psi})$ does not preserve orthogonality? Recall from \textbf{Section \ref{subsection:projective measurement}} and specifically \textbf{Example \ref{example: orthogonal states for measurements}} and \textbf{\ref{example: non-orthogonal states for measurements}} that it's very important to use an orthonormal basis for measurement because non-orthogonal states cannot be reliably distinguished.
So ideally $M(\ket{\psi})$ should preserve the orthogonality. Otherwise, say Alice makes a measurement on her part of $\ket{\psi}_{AB}$ using an orthonormal basis and gets an outcome with certainty, Bob will not be able to observe any outcome with certainty. So what is the characterization of matrices that preserve orthogonality?

\begin{prop} \label{orthogonality preserving character}
$\{M(\ket{\psi})|M(\ket{\psi})$ is a scalar multiple of a $n \times n$ unitary matrix$\}$ is a characterization of all states in $\mathbb{C}^n \otimes \mathbb{C}^n$ such that orthoganality is preserved. i.e. if $\braket{u|v}=0$, then $\braket{M(\ket{\psi})u|M(\ket{\psi}v}=0$.
\end{prop}

Let's first prove the following lemma.

\begin{lemma}
Any nonzero singular n by n matrix does not preserve orthogonality. In other words, for a nonzero singular $n \times n$ matrix M, there exist $\ket{u}, \ket{v} \in \mathbb{C}^n$ such that $\braket{u|v}=0$ but $\braket{Mu|Mv} \ne 0$.
\end{lemma}

\begin{proof}

Let the dimension of $ker(M)$ be m, and let $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}\}$ be a basis of $ker(M)$. Extend that basis to $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}, \hdots, \ket{x_n}\}$. Let
\begin{gather*}
    \ket{u}=\ket{x_1}+\ket{x_n}\\
    \ket{v}=\ket{x_1}-\ket{x_n}
\end{gather*}

Then $\braket{u|v}=(\bra{x_1}+\bra{x_n})(\ket{x_1}-\ket{x_n})=\braket{x_1|x_1}+\braket{x_n|x_1}-\braket{x_1|x_n}-\braket{x_n|x_n}=1+0-0-1=0$.

Since $\ket{x_1} \in ker(M)$, we also have
\begin{gather*}
    \ket{Mu}=M\ket{x_1}+M\ket{x_n}=M\ket{x_n}\\
    \ket{Mv}=M\ket{x_1}-M\ket{x_n}=-M\ket{x_n}    
\end{gather*}

Since $\ket{x_n} \notin ker(M)$, $\ket{\sigma}=M\ket{x_n} \ne 0$. So $\braket{Mu|Mv}=-\braket{\sigma|\sigma} \ne 0$.
\end{proof}

\bigskip
Now we are ready to prove Proposition \ref{orthogonality preserving character}.
\begin{proof}
Say $M(\ket{\psi})=\lambda U$, where $\lambda$ is a scalar and $U$ is a unitary matrix.
Then if $\braket{u|v}=0$, $\braket{M(\ket{\psi}u|M(\ket{\psi}v}=\braket{\lambda Uu|\lambda Uv}=\lambda^2 \braket{u|(U^\dagger U)v}=\lambda^2 \braket{u|v}=0$. So orthogonality is preserved.

\bigskip
Let's prove the other direction. Call $M(\ket{\psi})$ M (note that $M \ne 0$). Say $\braket{Mu|Mv}=0$ when $\braket{u|v}=0$. Then by the lemma, M must be a nonzero invertible matrix. 

Fix an arbitrary $v \in \mathbb{C}^n, v \ne 0$. Since M is a nonzero invertible matrix, $M^\dagger M v \ne 0$.

$\forall u \in \mathbb{C}^n$, if $\braket{u|v}=0$, then $\braket{Mu|Mv}=0$, so $\braket{u|M^\dagger Mv}=0$.

So $\forall u \in v^\perp, u \in (M^\dagger Mv)^\perp$. So $v^\perp \subseteq (M^\dagger Mv)^\perp$.

Since $v^\perp$ and $(M^\dagger Mv)^\perp$ both have dimension $n-1$, $v^\perp = (M^\dagger Mv)^\perp$.

So $\exists \lambda_v$ such that $\lambda_v v = M^\dagger M v$. We want to show that regardless of what v we pick initially, $\lambda_v$ stays the same. In other words, if we fix $v' \in \mathbb{C}^n, v' \ne 0, \lambda_{v'} v' = M^\dagger M v', \lambda_v = \lambda_{v'}$
\begin{gather*}
\braket{v|v'}-\braket{v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{M^\dagger M v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{v|M^\dagger M v'}=0\\
\Rightarrow \lambda_v \braket{v|v'}-\lambda_{v'} \braket{v|v'}=0\\
\Rightarrow (\lambda_v -\lambda_{v'}) \braket{v|v'}=0\\
\Rightarrow  \lambda_v = \lambda_{v'} if \braket{v|v'} \ne 0
\end{gather*}

If $\braket{v|v'}=0$, $\exists \ket{v''}$ such that $\braket{v|v''} \ne 0$ and $\braket{v'|v''} \ne 0$. Then $\lambda_v =\lambda_{v''}, \lambda_{v'}=\lambda_{v''}$. So $\lambda_v=\lambda_{v'}$ even when $\braket{v|v'}=0$.

So for an arbitrary $\ket{v} \in \mathbb{C}^n, \ket{v} \ne 0$, $\exists \lambda$ that's independent of $\ket{v}$ such that $M^\dagger M v = \lambda v$. So $M^\dagger M=\lambda \mathbb{I}_n\Rightarrow \frac{1}{\sqrt{\lambda}}M^\dagger \frac{1}{\sqrt{\lambda}} M=\mathbb{I}_n\Rightarrow M$ is a scalar multiple of a unitary matrix.
\end{proof}

What this theorem says is that if the coefficient matrix of a given shared quantum state $\ket{\psi}$ is a scalar multiplication of a unitary matrix, then if Alice picked the basis $\{\ket{u}, \ket{v}\}$ to measure on her qubit, Bob can measure his part with respect to the basis $\{M(\ket{\psi})\ket{u}, M(\ket{\psi})\ket{v}\}$. When $M(\ket{\psi})$ is a scalar multiple of a unitary matrix, it is also invertible and has full rank, so it's entangled as well. Therefore, Bob can infer Alice's measured outcome once he knows which specific basis Alice picked.

Otherwise, Bob can only measure with respect to some basis $\{M(\ket{\psi})\ket{u}, (M(\ket{\psi})\ket{u})^\perp \}$ and can only infer something meaningful of Alice within certain probability.


\begin{corollary}
$\ket{\psi}=\frac{1}{\sqrt{2}}(a\ket{00}+(-e^{i\theta})\Bar{b}\ket{01}+b\ket{10}+e^{i\theta}\Bar{a}\ket{11})$, where $a^2+b^2=1$ is a characterization of all states in $\mathbb{C}^2 \otimes \mathbb{C}^2$ such that if $\braket{u|v}=0$, then $\braket{M(\ket{\psi}u|M(\ket{\psi})v)}=0$.
\end{corollary}

\begin{example}
Consider a two-qubit joint state to be $\ket{\psi}=\frac{1}{\sqrt{2}}(\ket{00}+\ket{11})$. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$.
\end{example}
Then Bob will choose to measure on $\{M(\ket{\psi})\ket{0}, M(\ket{\psi})\ket{1}\}=\{\ket{1}, \ket{0}\}$. By Lemma \ref{end state lemma}, after Alice's measurement, if her outcome is $\ket{0}$, then Bob's post-measurement state will be $\ket{1}$. If her outcome is $\ket{1}
$, then Bob's post-measurement state will be $\ket{0}$. Because Bob chooses to measure on the standard basis, he will be able to observe the correct outcome $\ket{1}, \ket{0}$ respectively with certainty.

\begin{example}
Consider a two-qubit state not within the characterization in Proposition \ref{orthogonality preserving character} $\ket{\psi}=\frac{1}{\sqrt{3}}(\ket{00}+\ket{01}+\ket{10})$. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$.
\end{example}
Bob will not be able to measure on $\{M(\ket{\psi})\ket{0}, M(\ket{\psi})\ket{1}\}=\{\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}}
\end{pmatrix},\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
0
\end{pmatrix}\}$ because it's not orthogonal. So he will only be able to choose to measure on $\{M(\ket{\psi})\ket{0}, (M(\ket{\psi})\ket{0})^\perp \}$ or $\{(M(\ket{\psi})\ket{1})^\perp, M(\ket{\psi})\ket{1} \}$.
Without loss of generality, let's say Bob chooses to measure on $\{M(\ket{\psi})\ket{0}, (M(\ket{\psi})\ket{0})^\perp \}=\{\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}}
\end{pmatrix}, \begin{pmatrix}
\frac{1}{\sqrt{3}}\\
-\frac{1}{\sqrt{3}}
\end{pmatrix}\}$.
We normalize the two vectors and call them $\ket{u}'$ and $\ket{v}'$, respectively. So the orthonormal basis for Bob is $\{\ket{u'}, \ket{v'}\}$, where $\ket{u}'=\begin{pmatrix}
\frac{1}{\sqrt{2}}\\
\frac{1}{\sqrt{2}}
\end{pmatrix}$, $\ket{v}'=\begin{pmatrix}
\frac{1}{\sqrt{2}}\\
-\frac{1}{\sqrt{2}}
\end{pmatrix}$. Therefore to Bob, if he measures with basis $\ket{u'}, \ket{v'}$ and yields $\ket{v'}$, he can infer with certainty that Alice observes $\ket{1}$. However, if Bob yields $\ket{u'}$, then he is not able to tell what Alice observes.

\bigskip
\textcolor{red}{there needs to be some transition here.} Just by looking at \textbf{Lemma \ref{end state lemma}}, it seems that Alice can pick an arbitrary basis to make her measurement, and Bob shall receive a corresponding post-measurement state. However, what if the basis Alice picks contains a vector $\ket{u}$ that's within the kernel of coefficient matrix $M(\ket{\psi})$? Then according to the lemma, the post-measurement state will be a zero matrix, which is not a valid quantum state at all. Such incoherence is resolved by the following proposition.

\begin{prop} \label{null space}
Say Alice and Bob share a two-qudit quantum state $\ket{\psi}$. Alice can never observe an outcome $\ket{u}$ such that $\ket{\Bar{u}} \in Nul(M(\ket{\psi}))$.
\end{prop}
\begin{proof}
The shared density matrix is 
\begin{gather*}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}.  
\end{gather*}

Let $\ket{u}=\sum_1^n b_i \ket{e_i}$. Then
\begin{equation*} \tag{$\star$}
    \braket{u|i}=\overline{b_i}, \braket{i|u}=b_i
\end{equation*}

Since $\ket{\Bar{u}} \in Nul(M(\ket{\psi}))$, we have 
\begin{equation*} \tag{$\star \star$}
    \forall i, \sum_{j=1}^n a_{ij} \overline{b_i}=0
\end{equation*}

The probability of Alice observing $\ket{u}$, and Bob observing some $\ket{v}$ is
\begin{eqnarray*}
p(\ket{u}_A, \ket{v}_B)&=&\braket{u v | \rho |u v}\\
&=&\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\braket{u|i}\braket{i'|u}_A \otimes \braket{v|j}\braket{j'|v}_B\\
&=&\sum_i \sum_{i'} \sum_j \sum_{j'}  a_{ij} \overline{a_{i'j'}} \braket{u|i}\braket{i'|u}_A \otimes \braket{v|j}\braket{j'|v}_B\\
&=&(\sum_i \sum_j a_{ij} \overline{b_i})(\sum_{i'} \sum_{j'} \overline{a_{i'j'}} b_{i'})_A \otimes \braket{v|j}\braket{j'|v}_B   \; \; \;  (by (\star))\\ 
&=& 0 \; \; \; (by (\star \star))
\end{eqnarray*}
So Alice can never observe an outcome who's conjugate is in the kernel of $M(\ket{\psi})$.
\end{proof}

What the above proposition implies is that Alice can indeed choose an arbitrary orthonormal basis to make her measurement. Yet the possible outcomes she can observe are restricted to those not within the kernel of the coefficient matrix $M(\ket{\psi})$.
% Chapter Template

\chapter{Classification of Entanglement} % Main chapter title

\label{Chapter6-classification of entanglement} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{"actual entanglement".jpg}
    \caption{The First-Ever Photo of Quantum Entanglement captured by physicists at the University of Glasgow. \cite{moreau2019imaging}}
    \label{fig:actual entanglemen}
\end{figure}

When two particles are entangled, interacting with one immediately affects the other, regardless of how far apart they are in space.  It is no wonder that Albert Einstein once described entanglement as "spooky action at a distance". While we have defined entanglement (for states in {\bf{Definition}} \ref{definition: entanglement with state vector} and for density matrices in \textbf{Definition \ref{def: entanglement with density matrix}}) and used its properties (in the E91 Protocol laid out in \textbf{Section \ref{section: e91}}) it is natural to wonder {\emph{exactly}} when a composite system in $\mathbb{C}^n \otimes \mathbb{C}^n$ is entangled.
% How to classify entanglement for general 2-party composite systems in $\mathbb{C}^n \otimes \mathbb{C}^n$?
Also, are all entangled systems the same, or are some more entangled than others?  In this Chapter we answer these questions.

% In quantum mechanics one envisions Alice and Bob {\emph{sharing}} a potential entangled state.  When this happens we think of Alice's {\emph{part}} of the shared state as being the part on the {\emph{left-hand side}} of the tensor product, while Bob has the {\emph{right-hand side}}.  Note that we do not assume that the shared state is separable.

\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{"alice bob entanglement".png}
    \caption{Alice and Bob sharing an entangled state}
    \label{fig:entanglement}
\end{figure}

We will begin with a mathematical classification of when a vector in a tensor product of two vector spaces is a product of two vectors.  We apply this to the situation when Alice and Bob share a $2$-qudit quantum state in $\mathbb{C}^n \otimes \mathbb{C}^n$.  When this is the case, we first determine exactly when and to what extent the vectors on Alice's and Bob's side of the tensor product are correlated.  We then use this idea to ....  Lastly, we describe a procedure for using this machinery to make a one-time pad.

*****************************************************


Let $S$ denote the standard basis in $\mathbb{C}^n$. The convention is to think of the \textit{left} qudit of the 2-qudit quantum state as representing Alice's component system or particle, and the \textit{right} qudit of the shared 2-qudit state to be of Bob's. We can write $\ket{\psi}$ in terms of $S \otimes S$ and denote the coeffcients with a certain coefficient matrix. The next section serves to answer whether the rank of that coefficient matrix can be a well-defined tool to test if the state $\ket{\psi}$ is entangled and even further quantify the strength of entanglement.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------

\section{Rank of Coefficient Matrix and the Strength of Entanglement}
\begin{prop}
\label{rank prop}
Let $\ket{\psi}$ be a state in $\mathbb{C}^n \otimes \mathbb{C}^n$, and let $S=\{\ket{e_i}\}$ be the standard basis for $\mathbb{C}^n$. Let the coefficient matrix $M_{S \otimes S}(\ket{\psi})=(a_{i,j})$, where $\ket{\psi}=\sum\limits_{i,j}a_{i,j}|e_i e_j\rangle$.  Define $S(\ket{\psi})=\{m\in \mathbb{N}: \ket{\psi}=\sum_{i=1}^m\ket{v_i w_i}, for \ket{v_i}, \ket{w_i} \in \mathbb{C}^n\}$.  Then, $rank(M_{S \otimes S}(\ket{\psi}))=\textrm{min} (S(\ket{\psi})$.
% Thus in particular, the state $\ket{\psi}$ is a tensor product (not entangled) if and only if the matrix $M_{\ket{\psi}}$ is singular with rank one.
\end{prop}
This proposition shows that even though we can write $\ket{\psi}$ in different bases, the rank of the coefficient matrix associated with the standard basis is the smallest among all other coefficient matrices associated with other bases. To prove the proposition, we first prove the following lemma.

\begin{lemma}
\label{independence lemma}
Let $k=min S(\ket{\psi})$, and suppose $\ket{\psi}=\sum\limits_{i=0}^k \ket{v_iw_i}$.  Then $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ must both be linearly independent.
\end{lemma}

\begin{proof}
For a contradiction, let $k, \ket{\psi}, \ket{v_i}, \ket{w_i}$ be as above, and suppose that $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ is linearly dependent. Then without the loss of generality, say $\ket{v_k} \in span\{\ket{v_1}, \ket{v_2},...\ket{v_{k-1}}\}$. Then, $\ket{v_k}=\sum_i^{k-1} a_i \ket{v_i}$, for constants $a_i \in \mathbb{C}$.  Then, 
\begin{eqnarray*}
\ket{\psi}&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \ket{v_k w_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \sum_{i=1}^{k-1} a_i\ket{v_iw_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i} \otimes (\ket{w_i}+a_i\ket{w_k}).\\
\end{eqnarray*}

Apparently, $(k-1) \in S(\ket{\psi})$, contradicting the minimality of $k$.  Thus, $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_m}\}$ are linearly independent.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{rank prop}}.

\begin{proof}
Say $k=min(S(\ket{\psi}))$. Then, $\ket{\psi}=\sum_{i=1}^k \ket{v_i w_i}$, where $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ are linearly independent by Lemma \ref{independence lemma}.  Thus, we can extend each linearly independent set to bases for $\mathbb{C}^n$. Thus, let $B=\{\ket{v_1}, \ket{v_2},...,\ket{v_k}, \ket{v_{k+1}},...,\ket{v_n}\}$ and $B'=\{\ket{w_1}, \ket{w_2},...,\ket{w_n}\}$ be bases, and let $M_{B \otimes B'}(\ket{\psi})$ denote the coefficient matrix of $\ket{\psi}=\sum_{i=1}^{n}\ket{v_i w_i}$ with respect to the basis $B \otimes B'$. By inspection, 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_k && 0 \\
0 && 0
\end{pmatrix}$$
so $rank(M_{B \otimes B'}(\ket{\psi}))$ is k.

Thus, to show $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M_{S \otimes S}(\ket{\psi})$, we will find two invertible $n \times n$ matrices P, Q with $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$.

To do this, say $\ket{v_i}=\sum_{j=1}^n v_{ji}\ket{e_j}$, and
$\ket{w_i}=\sum_{j=1}^n w_{ji}\ket{e_j}$.  Since B and B' are both linearly independent, $P=(v_{i,j})$ and $Q=(w_{i,j})$ are both invertible.
% $P=\begin{pmatrix}
% \vert && \vert && \hdots && \vert\\
% \ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
% \vert && \vert && \hdots && \vert\\
% \end{pmatrix}$,\\
% $Q^{-1}=\begin{pmatrix}
% \text{---} && \ket{w_1}^T &&\text{---} \\
% \text{---} && \ket{w_2}^T &&\text{---} \\
% \vdots && \vdots && \vdots \\
% \text{---} && \ket{w_n}^T &&\text{---} \\
% \end{pmatrix}$.


Then, set $(b_{i,j})=PM_{B \otimes B'}(\ket{\psi})Q^{-1}$.  By direct computation, we have that
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

=\begin{pmatrix}
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}
\end{pmatrix}
\begin{pmatrix}
\text{---} && \ket{w_1}^T &&\text{---} \\
\text{---} && \ket{w_2}^T &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \ket{w_k}^T &&\text{---} \\
\text{---} && 0 &&\text{---}
\end{pmatrix}\\
=\begin{pmatrix}
v_{11}w_{11}+\hdots+v_{1k}w_{1k} && v_{11}w_{21}+\hdots+v_{1k}w_{2k} && \hdots && v_{11}w_{n1}+\hdots+v_{1k}w_{nk}\\
v_{21}w_{11}+\hdots+v_{2k}w_{1k} && v_{21}w_{21}+\hdots+v_{2k}w_{2k} && \hdots && v_{21}w_{n1}+\hdots+v_{2k}w_{nk}\\
\vdots && \vdots && \vdots && \vdots\\
v_{n1}w_{11}+\hdots+v_{nk}w_{1k} && v_{n1}w_{21}+\hdots+v_{nk}w_{2k} && \hdots && v_{n1}w_{n1}+\hdots+v_{nk}w_{nk}
\end{pmatrix}

\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{gather*}
    b_{ij}=\sum_{t=1}^k v_{it}w_{jt}
\end{gather*}


On the other hand,
\begin{eqnarray*}
\ket{\psi}&=&\sum_{i=1}^k \ket{v_i w_i}\\
&=&\sum_{i=1}^k \left(\sum_{j=1}^{n} v_{ji} \ket{e_j}) \otimes (\sum_{s=1}^n w_{si}\ket{e_s}\right)\\
&=&\sum_{i=1}^k \sum_{j=1}^{n} \sum_{s=1}^n v_{ji} w_{si} \ket{e_j e_s}\\
\end{eqnarray*}

\noindent
Thus, if $M_{S \otimes S}(\ket{\psi})=(a_{lr})$, then $a_{lr}=\sum_{i=1}^k v_{lk} w_{rk}=b_{lr}$.
So $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$.  Therefore, $rank(M_{S \otimes S}(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=k$.
\end{proof}

The computation above looks a bit complicated. You can verify it with the following example, the case when k=2, n=3.
\begin{example}
Consider the case where $k=2, n=3$.

Then 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_2 && 0 \\
0 && 0
\end{pmatrix}$$.

We want to show $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M_{S \otimes S}(\ket{\psi})=2$ by finding two $3\  \times 3$ invertible matrices P,Q such that $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$.
Let
\begin{gather*}
\ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
\ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\
P=(\ket{v_1}, \ket{v_2}, \ket{v_3})\\
Q^{-1}=(\ket{w_1}, \ket{w_2}, \ket{w_3})^T
\end{gather*}

Then
\begin{eqnarray*}
P M_{B \otimes B'}(\ket{\psi}) Q^{-1}&=&\begin{pmatrix}
v_{11} && v_{12} && v_{13}\\
v_{21} && v_{22} && v_{23}\\
v_{31} && v_{32} && v_{33}
\end{pmatrix}
\begin{pmatrix}
1 && 0 && 0\\
0 && 1 && 0\\
0 && 0 && 0\\
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11} && v_{12} && 0\\
v_{21} && v_{22} && 0\\
v_{31} && v_{32} && 0
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} \\
\end{pmatrix}
\end{eqnarray*}


% \ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
% \ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\

We also have
\begin{eqnarray*}
\ket{\psi}&=&\ket{v_1 w_1}+\ket{v_2 w_2}\\
&=& (v_{11}\ket{e_1}+v_{21}\ket{e_2}+v_{31}\ket{e_3}) \otimes (w_{11}\ket{e_1}+w_{21}\ket{e_2}+w_{31}\ket{e_3}) \\
&+& (v_{12}\ket{e_1}+v_{22}\ket{e_2}+v_{32}\ket{e_3}) \otimes (w_{12}\ket{e_1}+w_{22}\ket{e_2}+w_{32}\ket{e_1})\\
&=&\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} 
\end{pmatrix}
\end{eqnarray*}
So $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M_{S \otimes S}(\ket{\psi})$ and $rank(M_{S \otimes S}(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=2$.
\end{example}

\bigskip
If the rank of the coefficient matrix associated with the standard basis is 1, it follows from the \textbf{Proposition \ref{rank prop}} this corollary:

\begin{corollary}
If $rank(M(\ket{\psi}))=1$, then the state $\ket{\psi}$ is separable. Otherwise, $\ket{\psi}$ is entangled.
\end{corollary}

If the rank being 1 implies the joint quantum state is not entangled, what if the coefficent matrix has full rank? We now may make the following definition and proceed to classify the strength of entanglement in terms of the rank of the coefficient matrix. Here by strength, we mean how much information Bob has about Alice once Alice measures on her part of the composite system.

\begin{definition} \label{def: maximally entangled}
 Let $\ket{\psi}$ be a state in ${\mathbb{C}}^{(n^2)}$.  Then, the entanglement degree of $\ket{\psi}$ is $rank(M_{S \otimes S}(\ket{\psi}))$.  If the entanglement degree of $\ket{\psi}$ is $n$, we say $\ket{\psi}$ is maximally entangled \footnote{In some other literature, being maximally entangled means something different: A maximally entangled state is a quantum state which has maximum von Neumann entropy for each bipartition. This is equivalent to saying that the reduced density matrix $\rho_A, \rho_B$ are both a multiple of the identity matrix}.
\end{definition}

% When Alice and Bob share a state, Alice may measure her piece of the state, and if it is entangled, her measurement necessarily affects Bob's piece.

\begin{prop}
\label{entanglement-rank}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a 2-qudit quantum state shared by Alice and Bob. Say Alice first makes a measurement and observes $\ket{\varphi}$. Then the state of Bob's system \textit{after} Alice has performed the measurement but \textit{before} Bob has learned the measurement result is $\ket{\theta}\bra{\theta}$. Then the following statements about $\ket{\theta}$ hold.
\begin{enumerate}
    \item $rank(M(\ket{\psi}))=1$ if and only if $\ket{\theta}\bra{\theta}$ is a constant matrix that doesn't depend on $\ket{\varphi}$. The state of Bob's system contains no information about Alice.
    \item $rank(M(\ket{\psi}))=n$ if and only if $\ket{\psi}$ is maximally entangled. Then the state of Bob's system contains "maximal" information about Alice.
    \item If $1<rank(M(\ket{\psi}))<n$, then the state of Bob's system only contains some information about Alice.
\end{enumerate}
\end{prop}

This means in particular that if the rank is $n$, that what is on Bob's side of the tensor product is perfectly correlated with what is on Alice's side.  Thus, information about one side {\emph{in principle}} provides information about the other side. 

First, let's prove the following lemma.



% We now consider the use of the shared state $|X\rangle$ in message transmission.  Our goal is to classify exactly to what extent information can be transmitted remotely between two parties by use of shared states. The following lemma will tell us what happens in this situation when one of Alice or Bob observes a state $|\psi\rangle$.

\begin{lemma}
\label{end state lemma}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a quantum state representing a composite system of Alice and Bob.  The shared density matrix is therefore $\rho = \ket{\psi}\bra{\psi}$. Then,
\begin{enumerate}
\item Say Alice makes a measurement and observes $\ket{\varphi}\bra{\varphi}$, then Bob's post-measurement state is $\ket{\theta}\bra{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M_{\ket{\psi}}^T \overline{\ket{\varphi}}$.
\item Say Bob makes a measurement and observes observes $\ket{\varphi}\bra{\varphi}$, then Alice's post-measurement state is $\ket{\theta}\bra{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M_{\ket{\psi}}^T \overline{\ket{\varphi}}$.\\
C is just a scalar.
\end{enumerate}
\end{lemma}

\begin{proof}
First compute the shared density matrix in terms of the standard matrix.
\begin{equation}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}   
\end{equation}

Let $\ket{\varphi}=\icol{b_1\\ \vdots \\b_n}$.

Say Alice observes $\ket{\varphi}\bra{\varphi}_A$.
Then the post-measurement state conditioned on obtaining the outcome $\ket{\varphi}_A$ is
\begin{equation}
\rho_{\ket{\psi}_A}^{AB}=\frac{(\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB}(\ket{\varphi}\bra{\varphi}_A \otimes I_B)}{tr((\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB})}
\end{equation}

The denominator is just a scalar. Call it C. Then 
\begin{eqnarray}
\rho_{\ket{\psi}_A}^{AB}&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\ket{\psi}\braket{\psi|e_i}\braket{e_{i'}|\psi}\bra{\psi}_A \otimes \ket{e_j}\bra{e_{j'}}_B\\
&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}_B\\
&=&\ket{\varphi}\bra{\varphi}_A \otimes \frac{1}{c} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}
\end{eqnarray}

So the post-measurement state for Bob is
\begin{equation}
    \ket{\theta}\bra{\theta}=\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}} \\ \Rightarrow \ket{\theta}=\frac{1}{\sqrt{C}} M_{\ket{\psi}}^T \overline{\ket{\varphi}},
    \text{where } \overline{\ket{\varphi}}=\icol{\overline{b_1}\\ \vdots \\ \overline{b_n}}
\end{equation}
% Now let's compute C:
% \begin{align}
% tr((\ket{\psi}\bra{\psi}_A \otimes I_B)\rho_{AB})
% &=tr((\ket{\psi}\bra{\psi}_A \otimes I_B)(\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}_A \otimes \bra{e_{i'} e_{j'}}_B))\\
% &=\sum_{i,j} \sum_{i',j'} a_{ij}  \overline{a_{i'j'}}tr(\ket{\psi}\braket{\psi|e_i}\bra{e_{i'}})tr(\ket{e_j}\bra{e_{j'}})\\
% &=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}tr(\braket{e_{i'}|\psi}\braket{\psi|e_i})tr(\braket{e_{j'}|e_j})\\
% &=\sum_j \sum_i \sum_{i'} a_{ij} \overline{a_{i'j}}\overline{b_i}b_{i'}\\
% &=|\ket{\theta}|^2
% \end{align}
% The above computation makes use of the property that the trace of the tensor product of two matrices is just the product of the trace of each matrix. i.e. $tr(A \otimes B)=tr(A) \times tr(B)$. That trace is computable has also been used. C apparently just normalizes $\ket{\theta}$. In other words,
% \begin{equation}
%     \ket{\theta}=\frac{1}{\sqrt{C}} M_{\ket{\psi}}^T \overline{\ket{\varphi}}=\frac{M_{\ket{\psi}}^T \overline{\ket{\varphi}}}{|\ket{\theta}|}
%     \Rightarrow \frac{\ket{\theta}}{|\ket{\theta}|}=M_{\ket{\psi}}^T \overline{\ket{\varphi}}
% \end{equation}

% $tr((\ket{\psi}\bra{\psi}_A \otimes I_B)\rho_{AB})\\
% =tr((\ket{\psi}\bra{\psi}_A \otimes I_B)(\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}_A \otimes \bra{e_{i'} e_{j'}}_B))\\
% =\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}tr(\ket{\psi}\braket{\psi|e_i}\bra{e_{i'}})tr(\ket{e_j}\bra{e_{j'}})  $ 
% (by Proposition \ref{trace of tensor product})\\
% $=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}tr(\braket{e_{i'}|\psi}\braket{\psi|e_i})tr(\braket{e_{j'}|e_j})$ (since trace is commutable)\\
% $=\sum_j \sum_i \sum_{i'} a_{ij} \overline{a_{i'j}}\overline{b_i}b_{i'}$ (since $\braket{e_{j'}|e_j}=0$ when $j' \ne j$)\\
% $=|\ket{\theta}|^2$.

Similarly, say Bob observes $\ket{\varphi}\bra{\varphi}$. Then the post-measurement state conditioned on Bob obtaining the outcome $\ket{\psi}_B$ is $\rho_{\ket{\psi}_B}^{AB}=\frac{(I_A \otimes \ket{\psi}\bra{\psi}_B  )\rho_{AB}(I_A \otimes \ket{\psi}\bra{\psi}_B)}{tr((I_A \otimes \ket{\psi}\bra{\psi}_B)\rho_{AB})}$.
Then Alice's post-measurement state is $\ket{\theta}=\frac{1}{\sqrt{C}} M_{\ket{\psi}}^T \overline{\ket{\varphi}}$.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{entanglement-rank}}.
\begin{proof}
Let $M(\ket{\psi})=
\begin{pmatrix}
\vert && \vert && \hdots && \vert\\
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
\vert && \vert && \hdots && \vert\\
\end{pmatrix}$\\
Suppose $rank(M(\ket{\psi}))=m$. Without loss of generality, let $\ket{v_{m+1}}, \ket{v_{m+2}},...,\ket{v_n} \in span(\ket{v_1},\ket{v_2},...,\ket{v_m})$.\\
Then there exist scalar sets $\{\lambda_{(m+1),1}, \lambda_{(m+1),2},..., \lambda_{(m+1),m}\}, \{\lambda_{(m+2),1}, \lambda_{(m+2),2},..., \lambda_{(m+2),m}\},...,\\
\{\lambda_{n,1}, \lambda_{n,2},..., \lambda_{n,m}\}$ such that $\ket{v_{m+1}}=\sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i},...,\ket{v_n}=\sum_{i=1}^m \lambda_{n, i}\ket{v_i}$. Then

\begin{equation}
M(\ket{\psi})^T=\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}    
\end{equation}

When Alice observes $\ket{\psi}$, Bob is essentially trying to solve for the equation\\
\begin{equation}
\ket{\theta}= \frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\overline{\ket{\psi}}  
\end{equation}
Apparently, there are (n-m) free variables in $\overline{\ket{\psi}}$. This implies that the second statement and the third statement in \textbf{Proposition \ref{entanglement-rank}} are correct.

\bigskip
Let's prove the first statement in \textbf{Proposition \ref{entanglement-rank}}.

$(\Rightarrow):$ When $m=1$, 
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\text{---} && \lambda_2\ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \lambda_n\ket{v_1}^T &&\text{---} \\
\end{pmatrix}
\overline{\ket{\psi}}\\
=\frac{1}{\sqrt{C}}\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}
\end{equation}

Notice $C=(1+\lambda_2^2+\hdots+\lambda_n^2)n(\braket{\psi|v_1})^2$. So\\
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}\braket{\psi|v_1}}
\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\frac{\lambda_2}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\vdots\\
\frac{\lambda_n}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}
\end{pmatrix} 
\end{equation}
which is a constant vector that does not depend on $\ket{\psi}$.

\bigskip
$(\Leftarrow):$ Suppose $\ket{\theta}\bra{\theta}$ is a constant matrix that doesn't depend on $\ket{\psi}$. This means for an arbitrary $\ket{\psi}$, the normalized $M(\ket{\psi})^T \overline{\ket{\psi}}$ should always be equal to $\ket{\theta}$.

For contradiction, assume $rank(M(\ket{\psi})) \ge 2$. Let $\ket{\psi}=\ket{e_1}$. Then
\begin{equation}
\ket{\theta} = \frac{1}{\sqrt{C_1}}
\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\ket{e_1}
=\frac{1}{\sqrt{C_1}}
\begin{pmatrix}
v_{11}\\
v_{12}\\
\vdots\\
v_{1m}\\
\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}    
\end{equation}

Let $\ket{\psi}=\ket{e_2}$. Then
$\ket{\theta}=
\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}$.

Repeat the process until $\ket{\psi}=\ket{e_n}$. Then we get\\
$\ket{\theta}
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}
=\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}
=\hdots
=\begin{pmatrix}
\frac{1}{\sqrt{C_n}}v_{n1}\\
\frac{1}{\sqrt{C_n}}v_{n2}\\
\vdots\\
\frac{1}{\sqrt{C_n}}v_{nm}\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{(m+1), i} v_{ni}\\
\vdots\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{n, i} v_{ni}
\end{pmatrix}$\\
So $v_{11}:v_{21}:\hdots:v_{n1}=v_{12}:v_{22}:\hdots:v_{n2}=\hdots=v_{1m}:v_{2m}:\hdots:v_{nm}$.\\
Therefore $\{\ket{v_1}, \ket{v_2},\hdots, \ket{v_m}\}$ is linearly dependent.\\
So $rank(M(\ket{\psi})) = 1$. Contradiction!\\
So when $\ket{\theta}$ is a constant, the rank must be at least 2.\\
\end{proof}

\begin{example}
\textcolor{red}{include example for computing bob's end state after alice makes her measurement in $C^3$. what will happen probabilistically for bob after alice makes her measurement? also refer this back to postulate 3}
Say Alice and Bob share a state $\ket{\psi}=\frac{1}{2\sqrt{2}}(\ket{e_1 e_1}+\ket{e_2 e_3}+\ket{e_3 e_1}+\ket{e_3 e_3}$). Then Alice makes a measurement and yields $\ket{\varphi}$. 

Then from \textbf{Lemma \ref{end state lemma}}, Bob's post-measurement state is $\ket{\theta}\bra{\theta}$, $\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
1 && 0 && 1\\
0 && 0 && 0\\
0 && 1 && 1\\
\end{pmatrix}\overline{\ket{\varphi}}$
\end{example}

%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------

\section{Restrictions on Measurements?}
Now we know how Alice's and Bob's states are correlated mathematically during the "spooky action at a distance". Recall that in a previous \textbf{Section \ref{subsection:projective measurement}} , particularly in \textbf{Example \ref{example: orthogonal states for measurements}} and \textbf{\ref{example: non-orthogonal states for measurements}}, we say that we only want to make measurements on orthonormal basis, because otherwise states cannot be reliably distinguished. Before, the setup is that Alice chooses a state $\ket{\psi}_{i=1}^n$ from some fixed set of states known to both herself and to Bob. She then gives the state to Bob, whose task is to identify the index of that state. Now our task is different. Alice and Bob share a composite 2-qudit state $\ket{\psi}$. Suppose Bob knows the coefficient matrix of $\ket{\psi}$, $M_{\ket{\psi}}$, and the basis Alice measures with, $\ket{\psi}_{i=1}^n$. After Alice has made a measurement on her part of the system, the task is for Bob to infer Alice's result by only measuring on his part of the system. By \textbf{Lemma \ref{end state lemma}}, if the transpose of the coefficient matrix $M_{\ket{\psi}}$ preserves orthogonality, then Bob can measure with respect to the basis $M_{\ket{\psi}}^T \ket{\psi}_{i=1}^n$, which is automatically orthonormal. 

However, what would happen if $M_{\ket{\psi}}^T$ does not preserve orthogonality? Then $M_{\ket{\psi}}^T \ket{\psi}_{i=1}^n$ would no longer be orthonormal, and Bob will not be able to make a meaningful measurement. Therefore, in this section, we look to address what's the characterization of coefficient matrices that preserve orthogonality and explore what happens if orthogonality is not preserved.

\begin{prop} \label{orthogonality preserving character}
$\{M(\ket{\psi})|M(\ket{\psi})$ is a scalar multiple of a $n \times n$ unitary matrix$\}$ is a characterization of all states in $\mathbb{C}^n \otimes \mathbb{C}^n$ such that orthogonality is preserved. i.e. if $\braket{u|v}=0$, then $\braket{M(\ket{\psi})u|M(\ket{\psi}v}=0$.
\end{prop}

Let's first prove the following lemma.

\begin{lemma}
Any nonzero singular n by n matrix does not preserve orthogonality. In other words, for a nonzero singular $n \times n$ matrix M, there exist $\ket{u}, \ket{v} \in \mathbb{C}^n$ such that $\braket{u|v}=0$ but $\braket{Mu|Mv} \ne 0$.
\end{lemma}

\begin{proof}

Let the dimension of $ker(M)$ be m, and let $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}\}$ be a basis of $ker(M)$. Extend that basis to $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}, \hdots, \ket{x_n}\}$. Let
\begin{gather*}
    \ket{u}=\ket{x_1}+\ket{x_n}\\
    \ket{v}=\ket{x_1}-\ket{x_n}
\end{gather*}

Then $\braket{u|v}=(\bra{x_1}+\bra{x_n})(\ket{x_1}-\ket{x_n})=\braket{x_1|x_1}+\braket{x_n|x_1}-\braket{x_1|x_n}-\braket{x_n|x_n}=1+0-0-1=0$.

Since $\ket{x_1} \in ker(M)$, we also have
\begin{gather*}
    \ket{Mu}=M\ket{x_1}+M\ket{x_n}=M\ket{x_n}\\
    \ket{Mv}=M\ket{x_1}-M\ket{x_n}=-M\ket{x_n}    
\end{gather*}

Since $\ket{x_n} \notin ker(M)$, $\ket{\sigma}=M\ket{x_n} \ne 0$. So $\braket{Mu|Mv}=-\braket{\sigma|\sigma} \ne 0$.
\end{proof}

\bigskip
Now we are ready to prove Proposition \ref{orthogonality preserving character}.
\begin{proof}
Say $M(\ket{\psi})=\lambda U$, where $\lambda$ is a scalar and $U$ is a unitary matrix.
Then if $\braket{u|v}=0$, $\braket{M(\ket{\psi}u|M(\ket{\psi}v}=\braket{\lambda Uu|\lambda Uv}=\lambda^2 \braket{u|(U^\dagger U)v}=\lambda^2 \braket{u|v}=0$. So orthogonality is preserved.

\bigskip
Let's prove the other direction. Call $M(\ket{\psi})$ M (note that $M \ne 0$). Say $\braket{Mu|Mv}=0$ when $\braket{u|v}=0$. Then by the lemma, M must be a nonzero invertible matrix. 

Fix an arbitrary $v \in \mathbb{C}^n, v \ne 0$. Since M is a nonzero invertible matrix, $M^\dagger M v \ne 0$.

$\forall u \in \mathbb{C}^n$, if $\braket{u|v}=0$, then $\braket{Mu|Mv}=0$, so $\braket{u|M^\dagger Mv}=0$.

So $\forall u \in v^\perp, u \in (M^\dagger Mv)^\perp$. So $v^\perp \subseteq (M^\dagger Mv)^\perp$.

Since $v^\perp$ and $(M^\dagger Mv)^\perp$ both have dimension $n-1$, $v^\perp = (M^\dagger Mv)^\perp$.

So $\exists \lambda_v$ such that $\lambda_v v = M^\dagger M v$. We want to show that regardless of what v we pick initially, $\lambda_v$ stays the same. In other words, if we fix $v' \in \mathbb{C}^n, v' \ne 0, \lambda_{v'} v' = M^\dagger M v', \lambda_v = \lambda_{v'}$
\begin{gather*}
\braket{v|v'}-\braket{v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{M^\dagger M v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{v|M^\dagger M v'}=0\\
\Rightarrow \lambda_v \braket{v|v'}-\lambda_{v'} \braket{v|v'}=0\\
\Rightarrow (\lambda_v -\lambda_{v'}) \braket{v|v'}=0\\
\Rightarrow  \lambda_v = \lambda_{v'} if \braket{v|v'} \ne 0
\end{gather*}

If $\braket{v|v'}=0$, $\exists \ket{v''}$ such that $\braket{v|v''} \ne 0$ and $\braket{v'|v''} \ne 0$. Then $\lambda_v =\lambda_{v''}, \lambda_{v'}=\lambda_{v''}$. So $\lambda_v=\lambda_{v'}$ even when $\braket{v|v'}=0$.

So for an arbitrary $\ket{v} \in \mathbb{C}^n, \ket{v} \ne 0$, $\exists \lambda$ that's independent of $\ket{v}$ such that $M^\dagger M v = \lambda v$. So $M^\dagger M=\lambda \mathbb{I}_n\Rightarrow \frac{1}{\sqrt{\lambda}}M^\dagger \frac{1}{\sqrt{\lambda}} M=\mathbb{I}_n\Rightarrow M$ is a scalar multiple of a unitary matrix.
\end{proof}

What this theorem says is that if the coefficient matrix of a given shared quantum state $\ket{\psi}$ is a scalar multiplication of a unitary matrix, then if Alice picked the basis $\{\ket{u}, \ket{v}\}$ to measure on her qubit, Bob can measure his part with respect to the basis $\{M(\ket{\psi})\ket{u}, M(\ket{\psi})\ket{v}\}$. When $M(\ket{\psi})$ is a scalar multiple of a unitary matrix, it is also invertible and has full rank, so it's entangled as well. Therefore, Bob can infer Alice's measured outcome once he knows which specific basis Alice picked.

Otherwise, Bob can only measure with respect to some basis $\{M(\ket{\psi})\ket{u}, (M(\ket{\psi})\ket{u})^\perp \}$ and can only infer something meaningful of Alice within certain probability.


\begin{corollary}
$\ket{\psi}=\frac{1}{\sqrt{2}}(a\ket{00}+(-e^{i\theta})\Bar{b}\ket{01}+b\ket{10}+e^{i\theta}\Bar{a}\ket{11})$, where $a^2+b^2=1$ is a characterization of all states in $\mathbb{C}^2 \otimes \mathbb{C}^2$ such that if $\braket{u|v}=0$, then $\braket{M(\ket{\psi}u|M(\ket{\psi})v)}=0$.
\end{corollary}

\begin{example}
Consider a two-qubit joint state to be $\ket{\psi}=\frac{1}{\sqrt{2}}(\ket{00}+\ket{11})$. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$.
\end{example}
Then Bob will choose to measure on $\{M(\ket{\psi})\ket{0}, M(\ket{\psi})\ket{1}\}=\{\ket{1}, \ket{0}\}$. By Lemma \ref{end state lemma}, after Alice's measurement, if her outcome is $\ket{0}$, then Bob's post-measurement state will be $\ket{1}$. If her outcome is $\ket{1}
$, then Bob's post-measurement state will be $\ket{0}$. Because Bob chooses to measure on the standard basis, he will be able to observe the correct outcome $\ket{1}, \ket{0}$ respectively with certainty.

\begin{example}
Consider a two-qubit state not within the characterization in Proposition \ref{orthogonality preserving character} $\ket{\psi}=\frac{1}{\sqrt{3}}(\ket{00}+\ket{01}+\ket{10})$. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$.
\end{example}
Bob will not be able to measure on $\{M(\ket{\psi})\ket{0}, M(\ket{\psi})\ket{1}\}=\{\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}}
\end{pmatrix},\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
0
\end{pmatrix}\}$ because it's not orthogonal. So he will only be able to choose to measure on $\{M(\ket{\psi})\ket{0}, (M(\ket{\psi})\ket{0})^\perp \}$ or $\{(M(\ket{\psi})\ket{1})^\perp, M(\ket{\psi})\ket{1} \}$.
Without loss of generality, let's say Bob chooses to measure on $\{M(\ket{\psi})\ket{0}, (M(\ket{\psi})\ket{0})^\perp \}=\{\begin{pmatrix}
\frac{1}{\sqrt{3}}\\
\frac{1}{\sqrt{3}}
\end{pmatrix}, \begin{pmatrix}
\frac{1}{\sqrt{3}}\\
-\frac{1}{\sqrt{3}}
\end{pmatrix}\}$.
We normalize the two vectors and call them $\ket{u}'$ and $\ket{v}'$, respectively. So the orthonormal basis for Bob is $\{\ket{u'}, \ket{v'}\}$, where $\ket{u}'=\begin{pmatrix}
\frac{1}{\sqrt{2}}\\
\frac{1}{\sqrt{2}}
\end{pmatrix}$, $\ket{v}'=\begin{pmatrix}
\frac{1}{\sqrt{2}}\\
-\frac{1}{\sqrt{2}}
\end{pmatrix}$. Therefore to Bob, if he measures with basis $\ket{u'}, \ket{v'}$ and yields $\ket{v'}$, he can infer with certainty that Alice observes $\ket{1}$. However, if Bob yields $\ket{u'}$, then he is not able to tell what Alice observes.

%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------

\section{Is it possible to end up with an illegal "0" state?}
Just by looking at \textbf{Lemma \ref{end state lemma}}, it seems that Alice can pick an arbitrary basis to make her measurement, and Bob shall receive a corresponding post-measurement state. However, what if the basis Alice picks contains a vector $\ket{u}$ that's within the kernel of coefficient matrix $M(\ket{\psi})$? Then according to the lemma, the post-measurement state will be a zero matrix, which is not a valid quantum state at all. Such incoherence is resolved by the following proposition.

\begin{prop} \label{null space}
Say Alice and Bob share a two-qudit quantum state $\ket{\psi}$. Alice can never observe an outcome $\ket{u}$ such that $\ket{\Bar{u}} \in Nul(M(\ket{\psi}))$.
\end{prop}
\begin{proof}
The shared density matrix is 
\begin{gather*}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}.  
\end{gather*}

Let $\ket{u}=\sum_1^n b_i \ket{e_i}$. Then
\begin{equation*} \tag{$\star$}
    \braket{u|i}=\overline{b_i}, \braket{i|u}=b_i
\end{equation*}

Since $\ket{\Bar{u}} \in Nul(M(\ket{\psi}))$, we have 
\begin{equation*} \tag{$\star \star$}
    \forall i, \sum_{j=1}^n a_{ij} \overline{b_i}=0
\end{equation*}

The probability of Alice observing $\ket{u}$, and Bob observing some $\ket{v}$ is
\begin{eqnarray*}
p(\ket{u}_A, \ket{v}_B)&=&\braket{u v | \rho |u v}\\
&=&\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\braket{u|i}\braket{i'|u}_A \otimes \braket{v|j}\braket{j'|v}_B\\
&=&\sum_i \sum_{i'} \sum_j \sum_{j'}  a_{ij} \overline{a_{i'j'}} \braket{u|i}\braket{i'|u}_A \otimes \braket{v|j}\braket{j'|v}_B\\
&=&(\sum_i \sum_j a_{ij} \overline{b_i})(\sum_{i'} \sum_{j'} \overline{a_{i'j'}} b_{i'})_A \otimes \braket{v|j}\braket{j'|v}_B   \; \; \;  (by (\star))\\ 
&=& 0 \; \; \; (by (\star \star))
\end{eqnarray*}
So Alice can never observe an outcome who's conjugate is in the kernel of $M(\ket{\psi})$.
\end{proof}

What the above proposition implies is that Alice can indeed choose an arbitrary orthonormal basis to make her measurement. Yet the possible outcomes she can observe are restricted to those not within the kernel of the coefficient matrix $M(\ket{\psi})$.

The above classification of entanglement can potentially be used in the following cryptographic scheme.
\begin{enumerate}
    \item Bob creates a series of maximally entangled (as defined in \textbf{Definition \ref{def: maximally entangled}}) 2-qudit states $L={\ket{\psi_1}, \ket{\psi_2}, \hdots, \ket{\psi_m}}$, where $\ket{\psi_i} \in \mathbb{C}^n \otimes \mathbb{C^n}$. He sends the left qudit of each state to Alice via a quantum communication channel and keep the right side to himself.
    \item Via a classical communication channel that doesn't have to be secure, Alice notify Bob in order the set of orthonormal bases that she is going to make measurements with. In other words, for each $\ket{\psi_i}$, Alice randomly chooses an orthonormal basis $B_i=\{\ket{b_1}, \ket{b_2}, \hdots, \ket{b_n}\}$ and sends the elements in the basis in order to Bob.
    \item For each qudit received from L, Alice makes a measurement and saves her result locally. With the knowledge of L and $B_1, B_2, \hdots, B_m$, Bob will be able to infer Alice's measurement result by measuring with respect to basis $\{M_{\ket{\psi_i}}^T \ket{b_1}, M_{\ket{\psi_i}}^T \ket{b_2}, \hdots, M_{\ket{\psi_i}}^T \ket{b_n}\}$. He saves the result for each $\ket{\psi_i}$ and in the end get an m-digit long key that can be used for one-time pad introduced in \textbf{Definition \ref{def: quantum one-time pad}}.
\end{enumerate}
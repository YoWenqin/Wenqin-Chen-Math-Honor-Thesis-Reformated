% Chapter Template

\chapter{Classification of Entanglement} % Main chapter title

\label{Chapter6-classification of entanglement} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}
\begin{figure}[h]
    \centering
    \includegraphics[scale=0.4]{"actual entanglement".jpg}
    \caption{The First-Ever Photo of Quantum Entanglement captured by physicists at the University of Glasgow. \cite{moreau2019imaging}}
    \label{fig:actual entanglemen}
\end{figure}

When two particles are entangled, their states are so correlated that interacting with one immediately affects the other, even if they are far apart in space.  It is no wonder that Albert Einstein once described entanglement as "spooky action at a distance". While at this point we have defined entanglement (see {\bf{Definition}} \ref{definition: entanglement with state vector} and \textbf{Definition \ref{def: entanglement with density matrix}}) and used its properties (in the E91 Protocol laid out in \textbf{Section \ref{section: e91}}), it is natural to wonder {\emph{exactly}} when a composite state in $\mathbb{C}^n \otimes \mathbb{C}^n$ is entangled.
Are all entangled systems equivalent, or are there some systems that are more entangled than others? In this chapter we answer these questions.


We will begin with a mathematical classification of when a 2-qudit state is a tensor product of two vectors and determine to what extent Alice's vector and Bob's vector are correlated. In the case that Alice's and Bob's vectors are highly correlated, we then examine how Bob can use this correlation to make a one-time pad. 
% We will begin with a mathematical classification of when a vector in a tensor product of two vector spaces is a product of two vectors. We apply this to the situation when Alice and Bob share a $2$-qudit quantum state in $\mathbb{C}^n \otimes \mathbb{C}^n$. When this is the case, we first determine exactly when and to what extent the vectors on Alice's and Bob's side of the tensor product are correlated. If Alice and Bob's side of 
% We then use this idea to 


When Alice and Bob each have a system with state space ${\mathbb{C}}^n$, we know that their composite system will have state space ${\mathbb{C}}^n \otimes {\mathbb{C}}^n={\mathbb{C}}^{n^2}$ by Postulate 4 in \textbf{Chapter \ref{Chapter3-postulates}}. If $\ket{\psi}$ is the state vector for their composite system, the convention is to think of all terms on the left-hand side of the tensor product symbol as representing Alice's system, and all terms on the right-hand side as representing Bob's system.  

In the next Section we show that the rank of a matrix associated to a composite state $\ket{\psi}$ measures how entangled Alice's and Bob's systems are.

%----------------------------------------------------------------------------------------
%	SECTION 1
%----------------------------------------------------------------------------------------
\pagebreak

\section{Rank of Coefficient Matrix and the Strength of Entanglement}

We begin will a purely mathematical proposition which characterizes precisely when a vector in the tensor product of two vector spaces is a tensor product.

\begin{prop}
\label{rank prop}
Let $\ket{\psi}$ be a state in $\mathbb{C}^n \otimes \mathbb{C}^n$, and let $S=\{\ket{e_i}\}$ be the standard basis for $\mathbb{C}^n$. Define the coefficient matrix $M(\ket{\psi})$ by
\begin{equation}
M(\ket{\psi})=(a_{i,j}) \textrm{, where}\ket{\psi}=\sum\limits_{i,j}a_{i,j}|e_i e_j\rangle . 
\end{equation}
Also, set $S(\ket{\psi})=\{m\in \mathbb{N}: \ket{\psi}=\sum_{i=1}^m\ket{v_i w_i}, for \ket{v_i}, \ket{w_i} \in \mathbb{C}^n\}$.\\  Then, $rank(M(\ket{\psi}))=\textrm{min} (S(\ket{\psi})$.
\end{prop}

Notice in particular, that if $rank(M(\ket{\psi}))=1$, then there exist vectors $\ket{v_1}, \ket{w_1} \in \mathbb{C}^n$ with $\ket{\psi}=\ket{v_1}\ket{w_1}$.  Thus as a consequence of {\bf{Proposition}} \ref{rank prop}, we obtain a classification of entangled states.
\begin{corollary}
If $rank(M(\ket{\psi}))=1$, then the state $\ket{\psi}$ is separable. Otherwise, $\ket{\psi}$ is entangled.
\end{corollary}

While {\bf{Proposition}} \ref{rank prop} shows us that the rank of the coefficient matrix tells us whether or not $\ket{\psi}$ is entangled, we will later see that it is also a measure of {\emph{how entangled}} a composite system is. That is, we will show that in a precise way, the rank indicates the strength of the {\emph{correlation}} between Bob's and Alice's parts of the composite system.

Before continuing to discuss the connection between rank and entanglement, let's first prove a useful fact we will need in the proof of \textbf{Proposition \ref{rank prop}}.

\begin{lemma}
\label{independence lemma}
Let $k=min S(\ket{\psi})$, and suppose $\ket{\psi}=\sum\limits_{i=1}^k \ket{v_iw_i}$.  Then, the sets $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ are both linearly independent.
\end{lemma}

\begin{proof}
For a contradiction, let $k, \ket{\psi}, \{\ket{v_i}\}, \{\ket{w_i}\}$ be as above, and suppose that $\{\ket{v_1}, ...,\ket{v_k}\}$ is linearly dependent. Then, without loss of generality, say $\ket{v_k} \in span\{\ket{v_1}, \ket{v_2},...\ket{v_{k-1}}\}$. Then, $\ket{v_k}=\sum\limits_{i=1}^{k-1} a_i \ket{v_i}$, for constants $a_i \in \mathbb{C}$, and
\begin{eqnarray*}
\ket{\psi}&=&\sum\limits_{i=1}^{k-1} \ket{v_i w_i} + \ket{v_k w_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \left(\sum_{i=1}^{k-1} a_i\ket{v_i}\right) \otimes \ket{w_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i w_i} + \sum_{i=1}^{k-1} a_i\ket{v_iw_k}\\
&=&\sum_{i=1}^{k-1} \ket{v_i} \otimes (\ket{w_i}+a_i\ket{w_k}).\\
\end{eqnarray*}

Therefore $k-1 \in S(\ket{\psi})$, contradicting the minimality of $k$.  Thus, $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_m}\}$ are linearly independent as required.
\end{proof}

\bigskip
Now we are ready to prove \textbf{Proposition \ref{rank prop}}.

\begin{proof}
Let $k=min(S(\ket{\psi}))$ and say $\ket{\psi}=\sum\limits_{i=1}^k \ket{v_i w_i}$. By Lemma \ref{independence lemma}, $\{\ket{v_1}, \ket{v_2},...,\ket{v_k}\}$ and $\{\ket{w_1}, \ket{w_2},...,\ket{w_k}\}$ are linearly independent.  We now extend each linearly independent set to bases for $\mathbb{C}^n$. Thus, let $B=\{\ket{v_1}, \ket{v_2},...,\ket{v_k}, \ket{v_{k+1}},...,\ket{v_n}\}$ and $B'=\{\ket{w_1}, \ket{w_2},...,\ket{w_n}\}$ be bases, and let $M_{B \otimes B'}(\ket{\psi})$ denote the coefficient matrix of $\ket{\psi}=\sum\limits_{i=1}^{n}\ket{v_i w_i}$ with respect to the basis $B \otimes B'$. That is, $M_{B \otimes B'}(\ket{\psi})$ is the {\emph{coefficient matrix}} corresponding to the basis $\{\ket{v_i w_j} \}$ of ${\mathbb{C}}^{n^2}$.  By inspection, 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_k && 0 \\
0 && 0
\end{pmatrix}$$
so clearly $rank(M_{B \otimes B'}(\ket{\psi}))$ is k.

Thus, we need only show that $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M(\ket{\psi})$.  To do this, we will find two invertible $n \times n$ matrices P, Q with 
\begin{equation}
PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi}).
\end{equation}
Continuing, let $\ket{v_i}=\sum\limits_{j=1}^n v_{ji}\ket{e_j}$, and
$\ket{w_i}=\sum\limits_{j=1}^n w_{ji}\ket{e_j}$.  Since B and B' are both linearly independent, $P=(v_{i,j})$ and $Q=(w_{i,j})$ are both invertible.
% $P=\begin{pmatrix}
% \vert && \vert && \hdots && \vert\\
% \ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
% \vert && \vert && \hdots && \vert\\
% \end{pmatrix}$,\\
% $Q^{-1}=\begin{pmatrix}
% \text{---} && \ket{w_1}^T &&\text{---} \\
% \text{---} && \ket{w_2}^T &&\text{---} \\
% \vdots && \vdots && \vdots \\
% \text{---} && \ket{w_n}^T &&\text{---} \\
% \end{pmatrix}$.


Then, set $(b_{i,j})=PM_{B \otimes B'}(\ket{\psi})Q^{-1}$.  By direct computation, we have that
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

=\begin{pmatrix}
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}
\end{pmatrix}
\begin{pmatrix}
\text{---} && \ket{w_1}^T &&\text{---} \\
\text{---} && \ket{w_2}^T &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \ket{w_k}^T &&\text{---} \\
\text{---} && 0 &&\text{---}
\end{pmatrix}\\
=\begin{pmatrix}
v_{11}w_{11}+\hdots+v_{1k}w_{1k} && v_{11}w_{21}+\hdots+v_{1k}w_{2k} && \hdots && v_{11}w_{n1}+\hdots+v_{1k}w_{nk}\\
v_{21}w_{11}+\hdots+v_{2k}w_{1k} && v_{21}w_{21}+\hdots+v_{2k}w_{2k} && \hdots && v_{21}w_{n1}+\hdots+v_{2k}w_{nk}\\
\vdots && \vdots && \vdots && \vdots\\
v_{n1}w_{11}+\hdots+v_{nk}w_{1k} && v_{n1}w_{21}+\hdots+v_{nk}w_{2k} && \hdots && v_{n1}w_{n1}+\hdots+v_{nk}w_{nk}
\end{pmatrix}

\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{gather*}
    b_{ij}=\sum_{t=1}^k v_{it}w_{jt}
\end{gather*}


On the other hand,
\begin{eqnarray*}
\ket{\psi}&=&\sum_{i=1}^k \ket{v_i w_i}\\
&=&\sum_{i=1}^k \left(\sum_{j=1}^{n} v_{ji} \ket{e_j}) \otimes (\sum_{s=1}^n w_{si}\ket{e_s}\right)\\
&=&\sum_{i=1}^k \sum_{j=1}^{n} \sum_{s=1}^n v_{ji} w_{si} \ket{e_j e_s}\\
\end{eqnarray*}

\noindent
Thus, if $M(\ket{\psi})=(a_{lr})$, then $a_{lr}=\sum_{i=1}^k v_{lk} w_{rk}=b_{lr}$.
So $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi})$.  Therefore, $rank(M(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=k$.
\end{proof}

This establishes {\bf{Proposition}} \ref{rank prop}. To aid the reader, we include an example of the computation above done in the case when $k=2, n=3$.
\begin{example}
Consider the case where $k=2, n=3$.

Then 
$$M_{B \otimes B'}(\ket{\psi})=\begin{pmatrix}
\mathbb{I}_2 && 0 \\
0 && 0
\end{pmatrix}$$.

We want to show $rank(M_{B \otimes B'}(\ket{\psi}))=rank(M(\ket{\psi})=2$ by finding two $3\  \times 3$ invertible matrices P,Q such that $PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi})$.
Let
\begin{gather*}
\ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
\ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\
P=(\ket{v_1}, \ket{v_2}, \ket{v_3})\\
Q^{-1}=(\ket{w_1}, \ket{w_2}, \ket{w_3})^T
\end{gather*}

Then
\begin{eqnarray*}
P M_{B \otimes B'}(\ket{\psi}) Q^{-1}&=&\begin{pmatrix}
v_{11} && v_{12} && v_{13}\\
v_{21} && v_{22} && v_{23}\\
v_{31} && v_{32} && v_{33}
\end{pmatrix}
\begin{pmatrix}
1 && 0 && 0\\
0 && 1 && 0\\
0 && 0 && 0\\
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11} && v_{12} && 0\\
v_{21} && v_{22} && 0\\
v_{31} && v_{32} && 0
\end{pmatrix}
\begin{pmatrix}
w_{11} && w_{21} && w_{31}\\
w_{12} && w_{22} && w_{32}\\
w_{13} && w_{23} && w_{33}
\end{pmatrix}\\
&=&\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} \\
\end{pmatrix}.
\end{eqnarray*}


% \ket{v_i}=\sum_{j=1}^3 v_{ji}\ket{e_j}\\
% \ket{w_i}=\sum_{j=1}^3 w_{ji}\ket{e_j}\\

We also have
\begin{eqnarray*}
\ket{\psi}&=&\ket{v_1 w_1}+\ket{v_2 w_2}\\
&=& (v_{11}\ket{e_1}+v_{21}\ket{e_2}+v_{31}\ket{e_3}) \otimes (w_{11}\ket{e_1}+w_{21}\ket{e_2}+w_{31}\ket{e_3}) \\
&+& (v_{12}\ket{e_1}+v_{22}\ket{e_2}+v_{32}\ket{e_3}) \otimes (w_{12}\ket{e_1}+w_{22}\ket{e_2}+w_{32}\ket{e_1}).
\end{eqnarray*}
Therefore,
\begin{equation}
M(\ket{\psi})=
\begin{pmatrix}
v_{11}w_{11}+v_{12}w_{12} && v_{11}w_{21}+v_{12}w_{22} && v_{11}w_{31}+v_{12}w_{32}\\
v_{21}w_{11}+v_{22}w_{12} && v_{21}w_{21}+v_{22}w_{22} && v_{21}w_{31}+v_{22}w_{32} \\
v_{31}w_{11}+v_{32}w_{12} && v_{31}w_{21}+v_{32}w_{22} && v_{31}w_{31}+v_{32}w_{32} 
\end{pmatrix},
\end{equation}
so 
$$PM_{B \otimes B'}(\ket{\psi})Q^{-1}=M(\ket{\psi}).$$
Thus, we have established that $rank(M(\ket{\psi}))=rank(M_{B \otimes B'}(\ket{\psi}))=2$.
\end{example}



Our task is to now show our this mathematical description of entanglement is consistent with the correlation that motivated the phrase "spooky action at a distance". We point out that in the 1930s, Einstein was unhappy with the notion that an event at one point in space could influence another one far away, as if there is faster than light communication.  We examine a {\emph{real world}} situation where entanglement occurs, for example, when a laser beam is fired through a special kind of crystal to form a pair of entangled photons. Once either one of the photons is measured (as introduced in \textbf{Section \ref{subsection:projective measurement}}), the state of the entire entangled system {\emph{collapses}}.  In particular, the state of the other photon collapses as well, {\emph{although it may be very far away from the place where the measurement occurs.}} To explain this, Einstein theorized that the two photons contained some information that was hidden from us until the moment of measurement. While this "hidden information" idea ultimately was proven wrong by John Bell (see \textbf{Section \ref{section: bell-nonlocality}}), the fact remains that entanglement does allow for the {\emph{exchanging}} of information. In other words, even though Alice's photon may be at Smith College while Bob's is on Mars, Bob may be able to gain information about Alice's photon by measuring his. 

Next we will show that our "rank test" for entanglement can capture the correlation between the component states of composite system after measurement.  We now define the strength of entanglement of a composite system in terms of the coefficient matrix, and show that our notion is consistent with the degree to which the post-measurement states in a composite system are correlated.
% If the rank being 1 implies the joint quantum state is not entangled, what if the coefficent matrix has full rank? We now may make the following definition and proceed to classify the strength of entanglement in terms of the rank of the coefficient matrix. Here by strength, we mean how much information Bob has about Alice once Alice measures on her part of the composite system.

\begin{definition} \label{def: maximally entangled}
 Let $\ket{\psi}$ be a state in ${\mathbb{C}}^{(n^2)}$.  Then, the entanglement degree of $\ket{\psi}$ is $rank(M(\ket{\psi}))$.  If the entanglement degree of $\ket{\psi}$ is $n$, we say $\ket{\psi}$ is maximally entangled \footnote{This is not the standard definition of maximal entanglement.  More commonly, a maximally entangled states are ones with maximum von Neumann entropy for each bipartition. This is equivalent to saying that the reduced density matrix $\rho_A, \rho_B$ are both a multiple of the identity matrix}.
\end{definition}


Note that $\ket{\psi}$ is entangled exactly when it's entanglement degree is greater than one.  We now describe the composite system analogue of the situation described in \textbf{Example \ref{example: orthogonal states for measurements}} and \textbf{Example \ref{example: non-orthogonal states for measurements}}, where Bob tries to determine which state Alice picks from a known basis. 

We now introduce a {\emph{quantum version}} of the task in \textbf{Example \ref{example: orthogonal states for measurements}} and \textbf{Example \ref{example: non-orthogonal states for measurements}}. Alice and Bob now share a composite state which is known to both parties.  This time, instead of Alice {\emph{selecting}} an element of a basis, she {\emph{measures}} her part of the composite state with respect to an orthonormal basis, which is known to Bob (see \textbf{Figure \ref{fig:entanglement}}).  Thus {\emph{Alice's state}} will be her end state post-measurement, which is necessarily an element of the orthonormal basis.  Just like in the previous situation, the goal is for Bob to determine Alice's state with certainty.  


\begin{figure}[h]
    \centering
    \includegraphics[scale=0.8]{"entangled to alice and bob".png}
    \caption{Alice and Bob sharing an entangled state. Suppose that Alice measures with respect to an orthonormal basis $\{\varphi_i\}$ and obtains an end state $\ket{\varphi}$.  Then, the post-measurement state for Bob after Alice's measurement is $\ket{\theta}$. That is, their composite system has end state $\ket{\varphi}\otimes\ket{\theta}$}
    \label{fig:entanglement}
\end{figure}
% \textcolor{red}{add a tensor in between and a put a measurement sign only next to Alice}


We will see that there are two requirements that must be met if Bob is to be able to carry out his task with certainty.

\begin{quote} 
    {\bf{Requirement 1}} After Alice's measurement there must be a perfect correlation between Alice's end state $\ket{\varphi}$ and Bob's state $\ket{\theta}$.  That is to say, {\emph{if one knows}} $\ket{\theta}$ and Alice and Bob's shared composite state, then one can recover $\ket{\varphi}$.
    \medskip
    
    {\bf{Requirement 2}} Bob must be able to {\emph{access}} his state without creating additional uncertainty.
   
\end{quote}


We address the {\bf{Requirement 1}} in this section and {\bf{Requirement 2}} in the next section.  We wish to emphasize that (initially) {\emph{only Alice}} measures her part of their shared state with respect to an orthonormal basis.  Still, because of this measurement, the state of their composite system collapses.  


Suppose that Alice measures with respect to an orthonormal basis ${\{\ket{\varphi_i}\}}_{i=1}^{n}$.  Then, we know that for some $i_0$, she will observe outcome $i_0$, in which case her system will have $\ket{\varphi_{i_0}}$ as it's end state. Mechanically, we compute this in the case that she shares a composite state with Bob by converting their shared state $\ket{\psi}$ to a density matrix, and measuring with respect to the operators ${\{\ket{\varphi_i}\bra{\varphi_i}\otimes \mathbb{I} \}}_{i=1}^n$.  Thus, in what follows we consider the situation where Alice's system has state vector $\ket{\varphi}$ post-measurement.  This corresponds to the case where Alice is measuring with respect to {\emph{any}} orthonormal basis that contains $\ket{\varphi}$ as an element. Our task is to determine how correlated Bob's and Alice's states are after she has measured.  


% '\textcolor{blue}{We have to make sure enough is said about this version of the measurement computation.  I've changed some of them, but we can't call a state an "outcome".  Alice observes some outcome and the post-measurement state is psi.  Also, in the Proofs below, make sure we don't use any notation or computations that we haven't defined or shown}
% \textcolor{red}{outcome refers to the index instead of the actual state. check all of them.}

\textcolor{red}{add to the chapter in density matrix to justify our computation. change the prop to only use state}
\begin{prop}
\label{entanglement-rank}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a composite state shared by Alice and Bob. Say Alice first makes a measurement and observes an outcome with end state $\ket{\varphi}$. Let the state of Bob's system after Alice's measurement be denoted by $\ket{\theta}$. Then,
\begin{enumerate}
    \item $rank(M(\ket{\psi}))=1$ if and only if $\ket{\theta}$ is constant.  That is, $\ket{\theta}$ is independent of $\ket{\varphi}$. In this situation, the state of Bob's system has no correlation with Alice's measurement end state.
    \item $rank(M(\ket{\psi}))=n$ if and only if the state of Bob's system has perfect correlation with Alice's measurement end state.
    \item $1<rank(M(\ket{\psi}))<n$, then the state of Bob's system has partial correlation with Alice's measurement end state.
\end{enumerate}
\end{prop}

This means that when $\ket{\psi}$ is maximally entangled, after Alice has measured what is on Bob's side of the tensor product is perfectly correlated with what is on Alice's side.  When $\ket{\psi}$ is not entangled, there is no correlation at all between their end states.  On the other hand, if their joint state is entangled, but not maximally, there is some (but not perfect) correlation.  

Much of the proposition follows from the following lemma.  



% We now consider the use of the shared state $|X\rangle$ in message transmission.  Our goal is to classify exactly to what extent information can be transmitted remotely between two parties by use of shared states. The following lemma will tell us what happens in this situation when one of Alice or Bob observes a state $|\psi\rangle$.

\begin{lemma}
\label{end state lemma}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a composite state shared by Alice and Bob.  Then,
\begin{enumerate}
\item Say Alice makes a measurement and observes $\ket{\varphi}$, then Bob's state is $\ket{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M(\ket{\psi})^T \cdot \overline{\ket{\varphi}}$, where $C$ is a constant.
\item Similarly, if Bob was to make a measurement and observes $\ket{\varphi}$, then Alice's state is $\ket{\theta}$, where $\ket{\theta}=\frac{1}{\sqrt{C}}M(\ket{\psi})^T\cdot \overline{\ket{\varphi}}$, where $C$ is a constant.\\

\end{enumerate}
\end{lemma}

Thus, when Alice's post-measurement state is $\ket{\varphi}$, Bob's is given by left multiplication by $M(\ket{\psi})^T$ up to a global phase and taking conjugates.

\begin{proof}
As was discussed, we work with density matrices.  Thus, we first compute $\rho=\iota(\ket{\psi})=\ket{\psi}\bra{\psi}$.  Let $\ket{\psi}$ be given by 
\begin{equation}
\ket{\psi}=\icol{a_1\\ \vdots \\a_{n^2}}.
\end{equation}
Then, 

\begin{equation}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}   
\end{equation}

Now say
\begin{equation}
\ket{\varphi}=\icol{b_1\\ \vdots \\b_n}.
\end{equation}
Say Alice observes $\ket{\varphi}\bra{\varphi}_A$.
Then the post-measurement state conditioned on obtaining the end state $\ket{\varphi}_A$ is
\begin{equation}
\rho_{\ket{\varphi}_A}^{AB}=\frac{(\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB}(\ket{\varphi}\bra{\varphi}_A \otimes I_B)}{tr((\ket{\varphi}\bra{\varphi}_A \otimes I_B)\rho_{AB})}
\end{equation}

Let $C$ be the denominator of the above expression. Then 
\begin{eqnarray}
\rho_{\ket{\varphi}_A}^{AB}&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\ket{\varphi}\braket{\varphi|e_i}\braket{e_{i'}|\varphi}\bra{\varphi}_A \otimes \ket{e_j}\bra{e_{j'}}_B\\
&=&\frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}_B\\
&=&\ket{\varphi}\bra{\varphi}_A \otimes \frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}
\end{eqnarray}

So after Alice's measurement, Bob's state as a density matrix is given by
\begin{equation}
    \frac{1}{C} \sum_{i,j} \sum_{{i'}, {j'}} a_{ij} \overline{a_{i'j'}}\overline{b_i}b_{i'}\ket{e_j}\bra{e_{j'}}.
\end{equation}
By direct computation, this is equal to $\ket{\theta}\bra{\theta}$, where
\begin{equation}
    \ket{\theta}=\frac{1}{\sqrt{C}} M(\ket{\psi_i})^T \overline{\ket{\varphi}}.
\end{equation}

Thus, by {\bf{Lemma}} \ref{lemma state into density}, if Alice's end state is $\ket{\varphi}$, then Bob's is determined up to a global phase by multiplying the conjugate of Alice's state by transpose of the coefficient matrix.


By a similar computation, if instead Bob measures and observes end state $\ket{\varphi}\bra{\varphi}$, then Alice's post-measurement state is $$\ket{\theta}=\frac{1}{\sqrt{C}} M(\ket{\psi_i})^T \overline{\ket{\varphi}}$$.
\end{proof}

\medskip
We are now ready to prove \textbf{Proposition \ref{entanglement-rank}}.  Note that {\bf{Proposition}} \ref{entanglement-rank} follows from the following result.  We assume all the notation from the last lemma and proposition.
\begin{prop}
\label{correlation}
Suppose $rank({M(\ket{\psi})}^T)=m$, and let $j_1, j_2, ... j_m$ be the indices of the columns of the reduced row echelon form of $M(\ket{\psi})^T$ that have a leading one.  Suppose further that $\ket{\varphi} \in span\{\ket{e_{j_1}}, ... \ket{e_{j_m}}\}$.  Then if one knows $\ket{\theta}$, one can determine $\ket{\varphi}$ uniquely.  
\end{prop}
Thus, {\bf{Proposition}} \ref{correlation} says that if the $\ket{\psi}$ is maximally entangled,$\ket{\varphi}$ and $\ket{\theta}$ are perfectly correlated in the sense that from $\ket{\theta}$ one can {\emph{always}} uniquely determine $\ket{\varphi}$.  If $\ket{\psi}$ is entangled with entanglement degree $m<n$, then given $\ket{\theta}$ one can determine $\ket{\varphi}$ if we suppose first that $\ket{\varphi}$ lies in an $m$-dimensional subspace.  In this sense there is partial correlation between end states but not total correlation.  Note that when $\ket{\psi}$ is separable, {\bf{Proposition}} \ref{correlation} tells us that $\ket{\theta}$ conveys no information about $\ket{\varphi}$.  This is clear, since up to a global phase there is a unique state in the direction of $\ket{e_j}$ for any $j$.

We now prove {\bf{Proposition}} \ref{correlation}.
\begin{proof}
As in the proof of {\bf{Lemma}} \ref{end state lemma}, we work with density matrices here.  From {\bf{Lemma}} \ref{end state lemma},
\begin{eqnarray}
\ket{\theta}\bra{\theta}&=&{M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot({M(\ket{\psi})}^T\overline{\ket{\varphi}})^\dagger\\
&=&{M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot {(\overline{\ket{\psi}})}^\dagger {({M(\ket{\varphi})}^T)}^\dagger \\
&=&{M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot \overline{\bra{\varphi}} {({M(\ket{\psi})}^T)}^\dagger.
\end{eqnarray}
Now let $Y$ be the reduced row echelon form of $({M(\ket{\psi})}^T$ and let $A$ be the an $n$ by $n$ invertible matrix with
\begin{equation}
A \cdot ({M(\ket{\psi})}^T=Y.
\end{equation}
Then by our last computation,
\begin{eqnarray}
A\ket{\theta}\bra{\theta}A^\dagger&=&A {M(\ket{\psi})}^T\overline{\ket{\varphi}}\cdot \overline{\bra{\varphi}} {({M(\ket{\psi})}^T)}^\dagger A^\dagger\\
&=&Y \overline{\ket{\varphi}} \overline{\bra{\varphi}} Y^\dagger\\
&=& \ket{\tau}\bra{\tau},\textrm{ where }\ket{\tau}=Y\overline{\ket{\varphi}}.
\end{eqnarray}
Now, let 
\begin{equation}
\overline{\ket{\varphi}}=\icol{x_1 \\ \vdots \\ x_n} \textrm{ and }\ket{\tau}=\icol{z_1\\ \vdots \\ z_n}.
\end{equation}
Since $\ket{\varphi}$ is in the span of the the $\ket{e_{j_i}}$, $\overline{\ket{\varphi}}$ is as well.  Thus, since $Y$ is in reduced row echelon form, $x_{j_i}=z_i$.  But $\ket{\tau}$ is uniquely determined by {\bf{Lemma}} \ref{lemma state into density}.  Thus, by taking conjugates, we have determined $\ket{\varphi}$ uniquely as required.


\end{proof} 

\begin{comment}


**************************END*********************************
\begin{proof}
Let $$M(\ket{\psi})=
\begin{pmatrix}
\vert && \vert && \hdots && \vert\\
\ket{v_1} && \ket{v_2} && \hdots && \ket{v_n}\\
\vert && \vert && \hdots && \vert\\
\end{pmatrix}$$
Suppose $rank(M(\ket{\psi}))=m$.\\
Without loss of generality, let $\ket{v_{m+1}}, \ket{v_{m+2}},...,\ket{v_n} \in span(\ket{v_1},\ket{v_2},...,\ket{v_m})$, where $\ket{v_1}, ...\ket{v_m} $ are linearly independent.\\
Then there exist scalar sets 
\begin{gather}
\{\lambda_{(m+1),1}, \lambda_{(m+1),2},..., \lambda_{(m+1),m}\},\\
\{\lambda_{(m+2),1}, \lambda_{(m+2),2},..., \lambda_{(m+2),m}\},\\
\vdots\\
\{\lambda_{n,1}, \lambda_{n,2},..., \lambda_{n,m}\}    \end{gather}
 such that $\ket{v_{m+1}}=\sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i},...,\ket{v_n}=\sum_{i=1}^m \lambda_{n, i}\ket{v_i}$. Then

\begin{equation}
M(\ket{\psi})^T=\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}    
\end{equation}

When Alice observes $\ket{\psi}$, Bob is essentially trying to solve for the equation\\
\begin{equation}
\ket{\theta}= \frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\overline{\ket{\psi}}  
\end{equation}
Apparently, there are $n-m$ free variables in $\overline{\ket{\psi}}$. This implies that the second statement and the third statement in \textbf{Proposition \ref{entanglement-rank}} are correct.

\bigskip
Let's prove the first statement in \textbf{Proposition \ref{entanglement-rank}}.

$(\Rightarrow):$ When $m=1$, 
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{C}}\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\text{---} && \lambda_2\ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \lambda_n\ket{v_1}^T &&\text{---} \\
\end{pmatrix}
\overline{\ket{\psi}}\\
=\frac{1}{\sqrt{C}}\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}
\end{equation}

Notice $C=(1+\lambda_2^2+\hdots+\lambda_n^2)n(\braket{\psi|v_1})^2$. So\\
\begin{equation}
\ket{\theta}=\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}\braket{\psi|v_1}}
\begin{pmatrix}
\braket{\psi|v_1}\\
\lambda_2 \braket{\psi|v_1}\\
\vdots\\
\lambda_n \braket{\psi|v_1}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\frac{\lambda_2}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}\\
\vdots\\
\frac{\lambda_n}{\sqrt{n(1+\lambda_2^2+\hdots+\lambda_n^2)}}
\end{pmatrix} 
\end{equation}
which is a constant vector that does not depend on $\ket{\psi}$.

\bigskip
$(\Leftarrow):$ Suppose $\ket{\theta}\bra{\theta}$ is a constant matrix that doesn't depend on $\ket{\psi}$. This means for an arbitrary $\ket{\psi}$, the normalized $M(\ket{\psi})^T \overline{\ket{\psi}}$ should always be equal to $\ket{\theta}$.

For contradiction, assume $rank(M(\ket{\psi})) \ge 2$. Let $\ket{\psi}=\ket{e_1}$. Then
\begin{equation}
\ket{\theta} = \frac{1}{\sqrt{C_1}}
\begin{pmatrix}
\text{---} && \ket{v_1}^T &&\text{---} \\
\vdots && \vdots && \vdots\\
\text{---} && \ket{v_m}^T && \text{---} \\
\text{---} && \sum_{i=1}^m \lambda_{(m+1), i}\ket{v_i}^T  &&\text{---} \\
\vdots && \vdots && \vdots \\
\text{---} && \sum_{i=1}^m \lambda_{n, i}\ket{v_i}^T &&\text{---} \\
\end{pmatrix}\ket{e_1}
=\frac{1}{\sqrt{C_1}}
\begin{pmatrix}
v_{11}\\
v_{12}\\
\vdots\\
v_{1m}\\
\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}\\
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}    
\end{equation}

Let $\ket{\psi}=\ket{e_2}$. Then
$\ket{\theta}=
\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}$.

Repeat the process until $\ket{\psi}=\ket{e_n}$. Then we get\\
$\ket{\theta}
=\begin{pmatrix}
\frac{1}{\sqrt{C_1}}v_{11}\\
\frac{1}{\sqrt{C_1}}v_{12}\\
\vdots\\
\frac{1}{\sqrt{C_1}}v_{1m}\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{(m+1), i} v_{1i}\\
\vdots\\
\frac{1}{\sqrt{C_1}}\sum_{i=1}^m \lambda_{n, i} v_{1i}
\end{pmatrix}
=\begin{pmatrix}
\frac{1}{\sqrt{C_2}}v_{21}\\
\frac{1}{\sqrt{C_2}}v_{22}\\
\vdots\\
\frac{1}{\sqrt{C_2}}v_{2m}\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{(m+1), i} v_{2i}\\
\vdots\\
\frac{1}{\sqrt{C_2}}\sum_{i=1}^m \lambda_{n, i} v_{2i}
\end{pmatrix}
=\hdots
=\begin{pmatrix}
\frac{1}{\sqrt{C_n}}v_{n1}\\
\frac{1}{\sqrt{C_n}}v_{n2}\\
\vdots\\
\frac{1}{\sqrt{C_n}}v_{nm}\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{(m+1), i} v_{ni}\\
\vdots\\
\frac{1}{\sqrt{C_n}}\sum_{i=1}^m \lambda_{n, i} v_{ni}
\end{pmatrix}$\\
So $v_{11}:v_{21}:\hdots:v_{n1}=v_{12}:v_{22}:\hdots:v_{n2}=\hdots=v_{1m}:v_{2m}:\hdots:v_{nm}$.\\
Therefore $\{\ket{v_1}, \ket{v_2},\hdots, \ket{v_m}\}$ is linearly dependent.\\
So $rank(M(\ket{\psi})) = 1$. Contradiction!\\
So when $\ket{\theta}$ is non-constant, the rank must be at least 2.\\
\end{proof}



*********************************************************
\end{comment}



% \begin{example}
% \label{example rank full not orth}
% Include example where the n=3=rank, but the matrix is not a scalar multiple of a unitary matrix.
% \textcolor{red}{TODO. Only say there's perfect correlation. Say we will come back to this example in the next subsection.}
% \end{example}

Thus we have proven {\bf{Propositions}} \ref{entanglement-rank} and \ref{correlation}.  In practice, when a shared state is not maximally entangled, the failure of the correlation between Alice's and Bob's states to be total can be illustrated simply by observing what happens when measuring with respect to an orthonormal basis.  Here is an example showing what may happen when there is only partial correlation.
\begin{example}
\label{example rank not full}
Say Alice and Bob share a state $$\ket{\psi}=\frac{1}{2\sqrt{2}}(\ket{e_1 e_1}+\ket{e_2 e_3}+\ket{e_3 e_1}+\ket{e_3 e_3}).$$

Suppose Alice makes a measurement with respect to an unspecified orthonormal basis and observes end state  $\ket{\varphi}=\icol{a\\b\\c}$.  Then from \textbf{Lemma \ref{end state lemma}}, Bob's post-measurement state $\ket{\theta}$, where 
\begin{equation*} \label{eqn:example-theta}
\ket{\theta}=\frac{1}{\sqrt{C}}\left(\begin{smallmatrix}
1 && 0 && 1\\
0 && 0 && 0\\
0 && 1 && 1\\
\end{smallmatrix}\right)\overline{\ket{\varphi}}=\frac{1}{\sqrt{C}}\icol{
\overline{a+c}\\
0\\
\overline{b+c}}
\end{equation*}

 We now suggest a basis.  Say $\ket{\varphi} \in \{ \ket{\varphi}_i\}$, where this basis is given by
    \begin{gather}
    \ket{\varphi_1}=\ket{e_1}\\ \ket{\varphi_2}=\frac{1}{\sqrt{2}}(-\ket{e_2}+\ket{e_3})\\
    \ket{\varphi_3}=\frac{1}{\sqrt{2}}(-\ket{e_2}-\ket{e_3}).
    \end{gather}
Then, 
\begin{itemize}
\item $\textrm{if Alice has end state }\ket{\varphi_1} \textrm{, then Bob has end state } \ket{\theta_1}=\ket{e_1}$
\item $\textrm{if Alice has end state }\ket{\varphi_2} \textrm{, then Bob has end state} \ket{\theta_2}=\ket{e_1}$
\item $\textrm{if Alice has end state }\ket{\varphi_3} \textrm{, then Bob has end state }\ket{\theta_3}=\frac{1}{\sqrt{5}}(-\ket{e_1}-2\ket{e_3})$.
\end{itemize}


Thus, two different end states for Alice are paired with the same end state for Bob.  Because of this, Bob has no hope of distinguishing between Alice's outcomes $1$ and $2$.
\end{example} 
We emphasize that this does not occur for any orthonormal basis. For example, suppose Alice and Bob share the same state $\ket{\psi}$, but now she measures with respect to the standard orthonormal basis.  Then,

\begin{itemize}
\item if Alice has end state $\ket{e_1}$, then Bob has end state $\ket{e_1}$
\item if Alice has end state $\ket{e_2}$, then Bob has end state $\ket{e_3}$
\item if Alice has end state $\ket{e_3}$, then Bob has end state  $\frac{1}{\sqrt{2}}(\ket{e_1}+\ket{e_3})$.
\end{itemize}
Thus, when measuring with respect to this orthonormal basis, there is perfect correlation between Alice's measurement end state and Bob's post-measurement state even though $\ket{\psi}$ is not maximally entangled.  Therefore we see that the correlation depends on which orthonormal basis that Alice uses for measurement. So, at the level of bases only, the entanglement degree provides the \textit{worst case scenario} for correlation.

% Of course, we can use Gram-Schmidt to construct an orthonormal basis for $\mathbb{C}^3$ that contains both $\ket{\varphi}$ and $\ket{\varphi'}$. 


%  What this means is that for a coefficient matrix whose rank is neither 1 or the full rank, there exists some orthonormal basis that Alice can choose to measure on such that Bob will not be able to infer Alice's measurement result even if he knows the basis Alice chooses. Alice yielding $\ket{\varphi}$ and $\ket{\varphi'}$ will make no difference to what Bob observes on his side at all!






%----------------------------------------------------------------------------------------
%	SECTION 2
%----------------------------------------------------------------------------------------


Next, we take care of "old business" by proving that Bob's post-measurement state in \textbf{Lemma \ref{end state lemma}} is, in face, a {\emph{legal}} state.  The point is that a priori the conjugate of Alice's post-measurement state could be in the kernel of the transpose of the coefficient matrix $M(\ket{\psi})$. If this were the case, {\bf{Lemma}} \ref{end state lemma} tells us that the post-measurement state would be zero, which of course is not a valid state.  We now show that this occurs with probability zero.

\begin{prop} \label{null space}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^n$ be a composite state shared by Alice and Bob.  Then, Alice's end state after her measurement is not in $Nul(M(\ket{\psi})^T)$.
\end{prop}
\begin{proof}
We adopt all the notation from the proof of {\bf{Lemma}} \ref{end state lemma}.  Again, 
\begin{gather*}
\rho=\ket{\psi}\bra{\psi}=(\sum_{i,j} a_{ij}\ket{e_i e_j}(\sum_{i',j'} \overline{a_{i'j'}}\bra{e_{i'} e_{j'}})=\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}}.  
\end{gather*}

Consider an arbitrary dimensional qudit $\ket{u}=\sum\limits_1^n b_i \ket{e_i}$. Then
\begin{equation} \label{eqn: null space eqn 1}
    \braket{u|e_i}=\overline{b_i}, \textrm{and }\braket{e_i|u}=b_i
\end{equation}
We will show that if $\overline{\ket{u}}$ is in the kernel of left multiplication by $M(\ket{\psi})^T$, then the probability of Alice's measurement end state being $\ket{u}$ is $0$. Now suppose
$\ket{\Bar{u}} \in Nul(M(\ket{\psi})^T)$, we have \begin{equation} \label{eqn: null space eqn 2}
    \forall i, \sum_{j=1}^n a_{ji} \overline{b_j}=0
\end{equation}
\textcolor{red}{reference where the formula for calculating the probability comes from. add the formula into the density matrix section and have the games reference the formula as well. why can we calculate the probability as if Alice and Bob are measuring at the same time? }
\textcolor{blue}{I changed the index above which was switched.  What's going on in this proof below?  What identity are we using}
\begin{eqnarray*}
p(\ket{uv})&=&\braket{u v | \rho |u v}\\
&=&\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\braket{u|e_i}\braket{e_{i'}|u}_A \otimes \braket{v|e_j}\braket{e_{j'}|v}_B\\
&=&\sum_i \sum_{i'} \sum_j \sum_{j'}  a_{ij} \overline{a_{i'j'}} \braket{u|e_i}\braket{e_{i'}|u}_A \otimes \braket{v|j}\braket{j'|v}_B\\
&=&(\sum_i \sum_j a_{ij} \overline{b_i})(\sum_{i'} \sum_{j'} \overline{a_{i'j'}} b_{i'})_A \otimes \braket{v|j}\braket{j'|v}_B   \; \; \;  (by \;  \eqref{eqn: null space eqn 1})\\ 
&=& 0 \; \; \; (by \; \eqref{eqn: null space eqn 2})
\end{eqnarray*}





******************************************************



\textcolor{blue}{****************ALTERNATE PROOF with no need for computational justification}

Let $\ket{e_r}$ be an element of the standard basis.  Then,
\begin{eqnarray*}
p(\ket{ue_r})&=&\braket{ue_r | \rho |ue_r}\\
&=&\braket{ue_r| (\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}})|ue_r} \\
&=&\braket{\sum_k b_ke_k e_r| (\sum_{i,j} \sum_{i',j'} a_{ij} \overline{a_{i'j'}}\ket{e_i e_j}\bra{e_{i'} e_{j'}})|\sum_{k'}b_{k'}e_{k'}e_r}\\
&=&\sum_{k,k'}\sum_{i,j}\sum_{i',j'}\overline{b_k}a_{i,j}\overline{a_{i',j'}}b_{k'}\braket{e_k e_r|e_i e_j}\braket{e_{i,}e_{j'}|e_{k'}e_r}\\
&=&\sum_{k,k'}\overline{b_k}a_{k,r}\overline{a_{k',r}}b_{k'},
\end{eqnarray*}
since the inner products are nonzero only when $i=i'=k$ and $j=j'=r$.  But
\begin{equation*}
\sum_{k,k'}\overline{b_k}a_{k,r}\overline{a_{k',r}}b_{k'}=\sum_k \sum_{k'} \overline{b_k}a_{k,r}\overline{a_{k',r}}b_{k'}
=\sum_k \overline{b_k}a_{k,r} \sum_{k'}\overline{a_{k',r}}b_{k'}
=0\cdot 0=0, \textrm{ by }\eqref{eqn: null space eqn 2}.
\end{equation*}

Thus, the probability of the end state $\ket{u e_r}=0$ for every $r$ with $1\leq r \leq n$.  But then for any $\ket{v} \in {\mathbb{C}}^n$, the end state $\ket{uv} = \ket{u}\otimes\ket{v}$ occurs with probability zero, hence Alice cannot have end state $\ket{u}$.
\end{proof}


\textcolor{blue}{********************* End alternate proof*************************************}


******************************************************



We have now described exactly when there exists perfect correlation between Alice's measurement end state $\ket{\varphi}$ and Bob's post-measurement state $\ket{\theta}$ after Alice measures.  We therefore know precisely when the first requirement necessary for Bob to determine Alice's outcome is satisfied.  However, if Bob is not able to perform {\emph{his own measurement}} on his end state without introducing uncertainty, having a "perfect" correlation with Alice is not enough. In the next section we move on to {\bf{Requirement 2}}, and determine exactly when Bob can determine Alice's outcome with certainty.


%----------------------------------------------------------------------------------------
%	SECTION 3
%----------------------------------------------------------------------------------------
\pagebreak

\section{Entanglement and Measuring}
In the last section we analyzed the extent to which Alice's and Bob's end states are correlated when Alice measures a shared composite state. We now continue with our analysis, focusing on when Bob has {\emph{access}} to his state vector without introducing additional uncertainty. 
% This situation is similar to that of \textbf{Examples \ref{example: orthogonal states for measurements}} and \textbf{\ref{example: non-orthogonal states for measurements}}, only now instead of Alice {\emph{selecting}} a state, now she {\emph{measures}} and observes an outcome with an end state.  Specifically, in our previous setup, Alice chooses a state from an orthonormal basis $\{\ket{\varphi_i}\}_{i=1}^n$ known to both herself and to Bob. She then gives the state to Bob, whose task is to identify the index of that state. Our task is different. Now, Alice and Bob share a known composite 2-qudit state $\ket{\psi}$ and Alice measures with respect to the orthonormal basis. 

By \textbf{Lemma \ref{end state lemma}}, if the transpose of the coefficient matrix $M(\ket{\psi_i})$ preserves orthogonality and has full rank, Bob can measure with respect to the basis $\{M(\ket{\psi_i})^T \overline{\ket{\psi_i}}\}_{i=1}^n$, which must be orthonormal. Thus, by measuring with respect to {\emph{this}} orthonormal basis he will be able to infer which end state Alice observed by simply applying the inverse of the transpose of the coefficient matrix to the his end state, and then taking conjugates. This is very much the quantum analogue of {\bf{Example}} \ref{example: orthogonal states for measurements}.

On the other hand, if the transpose of the coefficient matrix does not preserve orthogonality, Bob cannot determine Alice's end state with certainty {\emph{even if their shared state is maximally entangled}}.  Thus, perfect correlation between Alice's and Bob's end states is not enough to guarantee that he knows the results of her measurement.  This is because even though their end states may be perfectly correlated, uncertainty is introduced when Bob tries to {\emph{access}} his end state by measuring, as was the case in {\bf{Example}} \ref{example: non-orthogonal states for measurements}.  The next Proposition characterizes exactly when Bob is able to infer Alice's measurement end state with certainty.  
% \textcolor{red}{I think I had that $\ket{\psi}$ must be maximally entangled in the below proposition. Is that not needed? }

\begin{prop} \label{prop: ultimate}
Let $\ket{\psi} \in \mathbb{C}^n \otimes \mathbb{C}^{n}$ be a composite state shared by Alice and Bob. Say Alice makes a measurement with respect to a basis known to both herself and Bob.  Then, Bob can determine Alice's end state with certainty if and only if the transpose of the coefficient matrix preserves orthogonality.
\end{prop}

\begin{proof}
This result follows from the calculations in the proof of \textbf{Proposition \ref{entanglement-rank}}, and the fact that a nonzero matrix which preserves orthogonality must be of full rank and is therefore maximally entangled.  Thus after {\bf{Proposition}} \ref{orthogonality preserving character} the result is proven.
\end{proof}




\begin{prop} \label{orthogonality preserving character}
Let $M$ be a square matrix.  Then $M$ is a nonzero scalar multiple of a unitary matrix if and only if $M$ is not identically zero and preserves orthogonality.

\end{prop}



\begin{proof}
First, let $M$ be a nonzero scalar multiple of a unitary matrix. Say $M=\lambda U$, where $\lambda \ne 0$, and $U$ is a unitary matrix.  Suppose that $\braket{u|v}=0$.  Then,
$$\braket{Mu|Mv}=\braket{\lambda Uu|\lambda Uv}={|\lambda|}^2 \braket{u|(U^\dagger U)v}={|\lambda|}^2 \braket{u|\mathbb{I}v}={|\lambda|}^2 \braket{u|v}0,$$ So orthogonality is preserved.  Thus nonzero scalar multiples of unitary matrices preserve orthogonality.

Now suppose $M\neq0$, and $\braket{Mu|Mv}=0$ when $\braket{u|v}=0$. First, we will show that $M$ must be invertible.  We prove the contrapositive.  That is, if a nonzero $n$ by $n$ matrix $M$ is singular, there exist $\ket{u}, \ket{v} \in \mathbb{C}^n$ such that $\braket{u|v}=0$, but $\braket{Mu|Mv} \ne 0$.

Say $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}\}$ is a basis for $ker(M)$, and extend to $\{\ket{x_1}, \ket{x_2},\hdots, \ket{x_m}, \hdots, \ket{x_n}\}$ a basis for ${\mathbb{C}}^n$.  By hypothesis on $M$, $1 \leq m <n$, and by Gram-Schmidt we may assume that this basis is orthonormal.  Let
\begin{gather*}
    \ket{u}=\ket{x_1}+\ket{x_n}\\
    \ket{v}=\ket{x_1}-\ket{x_n}
\end{gather*}

Then $\braket{u|v}=(\bra{x_1}+\bra{x_n})(\ket{x_1}-\ket{x_n})=\braket{x_1|x_1}+\braket{x_n|x_1}-\braket{x_1|x_n}-\braket{x_n|x_n}=1+0-0-1=0$.

Since $\ket{x_1} \in ker(M)$, we also have
\begin{gather*}
    \ket{Mu}=M\ket{x_1}+M\ket{x_n}=M\ket{x_n}\\
    \ket{Mv}=M\ket{x_1}-M\ket{x_n}=-M\ket{x_n}    
\end{gather*}

Since $\ket{x_n} \notin ker(M)$, we have $\ket{\sigma}=M\ket{x_n} \ne 0$. So $\braket{Mu|Mv}=-\braket{\sigma|\sigma} \ne 0$. Thus $M$ does not preserve orthogonality, so any matrix which preserves orthogonality must be invertible.  We now show that a nonzero matrix $M$ which preserves orthogonality must be a scalar multiple of a unitary matrix.

Let $\ket{v} \in \mathbb{C}^n, \ket{v} \ne 0$.  Since $M$ is a nonzero invertible matrix, $M^\dagger M \ket{v} \ne 0$.  Now, for $\ket{u} \in \mathbb{C}^n$, if $\braket{u|v}=0$, then $\braket{Mu|Mv}=0$, so $\braket{u|M^\dagger Mv}=0$, thus
$$\ket{v}^\perp \subseteq {(M^\dagger M\ket{v})}^\perp.$$

\noindent
Since $\ket{v}^\perp$ and $(M^\dagger M\ket{v})^\perp$ both have dimension $n-1$, $\ket{v}^\perp = (M^\dagger M\ket{v})^\perp$, thus for some $\lambda_v \in \mathbb{C}$, we have $\lambda_v \ket{v} = M^\dagger M \ket{v}.$

Now let $0 \neq \ket{v'} \in \mathbb{C}^n$ with $\braket{v|v'} \neq 0$, and let ${\lambda}_{v'}=M^\dagger M \ket{v'}$.  Then,
\begin{gather*}
\braket{v|v'}-\braket{v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{M^\dagger M v|v'}=0\\
\Rightarrow \braket{M^\dagger M v|v'}-\braket{v|M^\dagger M v'}=0\\
\Rightarrow \lambda_v \braket{v|v'}-\lambda_{v'} \braket{v|v'}=0\\
\Rightarrow (\lambda_v -\lambda_{v'}) \braket{v|v'}=0\\
\Rightarrow  \lambda_v = \lambda_{v'}.
\end{gather*}

On the other hand, if $\braket{v|v'}=0$, then $ \ket{v''}=\ket{v}+\ket{v'}$ is not orthogonal to both $\ket{v}$, $\ket{v'}$.  Thus, 
$$ {\lambda}_{v}=\lambda_{v''}=\lambda_{v'}.$$

Thus, since $\lambda$ is independent of $\ket{v}$, $M^\dagger M = \lambda \mathbb{I}$.  But then,
\begin{equation*}
{(M^\dagger M)}^\dagger={(\lambda \mathbb{I})}^\dagger=\overline{\lambda} \mathbb{I} =\lambda \mathbb{I}.
\end{equation*}
So $\lambda$ is real and  
\begin{equation*}
{(\frac{1}{\sqrt{\lambda}}M)}^\dagger \frac{1}{\sqrt{\lambda}}M=\frac{1}{\lambda}M^\dagger M=\frac{1}{\lambda}\lambda\mathbb{I}=\mathbb{I},
\end{equation*}
so $M$ is a scalar multiple of a unitary matrix as required.
\end{proof}



Thus, after Alice has made her measurement with respect to an orthonormal basis $\{\ket{\varphi_i}\}_{i=1}^n$, Bob is guaranteed to be able to measure with respect to the basis $\{M(\ket{\psi})^T {\overline{\ket{\varphi_i}}}\}_{i=1}^n$, only if the transpose of the coefficient matrix $M(\ket{\psi})^T$ is a scalar multiple of a unitary matrix. 

For example, say $M(\ket{\psi})^T$ is a scalar multiple of a unitary matrix.  Then, if Alice measured her part of the shared system with respect to a basis $\{\ket{u}, \ket{v}\}$, then 
Bob can measure his part with respect to the orthonormal basis $\{M(\ket{\psi})^T\overline{\ket{u}}, M(\ket{\psi})^T\overline{\ket{v}}\}$. In this situation, not only is the state of Bob's system perfectly correlated with Alice's by \textbf{Proposition \ref{entanglement-rank}}, but Bob can measure with respect to an orthonormal basis consisting of all of his possible end states.  Therefore, by measuring his system with respect to $\{M(\ket{\psi})^T\overline{\ket{u}}, M(\ket{\psi})^T\overline{\ket{v}}\}$, Bob can infer Alice's end state that is either $\ket{u}$, or $\ket{v}$.
% Therefore, Bob can infer Alice's measured outcome once he knows which specific basis Alice picked.

On the other hand, if $\ket{\psi}$ is maximally entangled, but it's coefficient matrix doesn't have the desired form, Bob may have to measure with respect to an orthonormal basis of the form $\{M(\ket{\psi})^T\overline{\ket{u}}, (M(\ket{\psi})^T\overline{\ket{u})}^\perp \}$.  In this case, Bob cannot infer Alice's outcome perfectly, even though prior to {\emph{his}} measurement, there was perfect correlation between his and Alice's end states.  

In our first example, we illustrate what happens when both {\bf{Requirements 1, 2}} are satisfied.
\begin{example}
\label{example good}
Let $\ket{\psi}=\frac{1}{\sqrt{2}}(\ket{01}+\ket{10})$ be a composite state shared by Alice and Bob.  Say Alice chooses to measure with respect to the standard basis $\{\ket{0}, \ket{1}\}$.  Then,
\begin{equation*}
M(\ket{\psi})=M(\ket{\psi})^T= \frac{1}{\sqrt{2}}\left(\begin{smallmatrix}0 & 1\\1 & 0\end{smallmatrix}\right),
\end{equation*}
which is a scalar multiple of a unitary matrix since,
\begin{equation*}
\left(\begin{smallmatrix}0 & 1\\1 & 0\end{smallmatrix}\right)\cdot \left(\begin{smallmatrix}0 & 1\\1 & 0\end{smallmatrix}\right)=\mathbb{I}.
\end{equation*}
Therefore, by \textbf{Proposition \ref{prop: ultimate}}, Bob can determine Alice's measurement end state with certainty. This is because he can measure with respect to the orthonormal basis
\begin{equation*}
\{\left(\begin{smallmatrix}0 & 1\\1 & 0\end{smallmatrix}\right)\ket{0}, \left(\begin{smallmatrix}0 & 1\\1 & 0\end{smallmatrix}\right)\ket{1}\}=\{\ket{1}, \ket{0}\}=\{\ket{\theta_1},\ket{\theta_2}\}.
\end{equation*}

By Lemma \ref{end state lemma} after Alice's measurement, if Alice observes outcome $1$, her end state is $\ket{0}$, in which case the composite system is in state $\ket{\varphi}\otimes \ket{\theta}=\ket{0}\otimes\ket{1}=\ket{01}$.  The key point, is that when Bob measures the post-measurement system, he observes the outcome $1$ and end state $\ket{1}$ with probability one.  Since he knows both Alice's basis and the state $\ket{\psi}$, he can determine her outcome by multiplying by the inverse of transpose of the coordinate matrix and taking conjugates, and then picking the outcome which matches that state.  Thus, in this case, he multiplies his end state by $\left(\begin{smallmatrix}0&1\\1&0\end{smallmatrix}\right)$ and gets $\ket{0}$, so he knows that she observed outcome $1$  and had end state $\ket{0}$.

Similarly, if Alice observes outcome $2$, her end state is $\ket{1}$, in which case the composite system is in state $\ket{\varphi}\otimes\ket{\theta}=\ket{1}\otimes \ket{0}=\ket{10}$.  In this situation, when Bob measures he observes $2$ and has end state $\ket{0}$ with probability one.  Again, by multiplying his end state by the inverse of the transpose of the coefficient matrix, he can determine Alice's end state, and hence her outcome with certainty.
\end{example}




We now consider another example.




\begin{example}
\label{example bad}
Let $\ket{\psi}=\frac{1}{\sqrt{3}}(\ket{00}+\ket{01}+\ket{10})$ be a composite state shared by Alice and Bob. Say Alice chooses to measure on the standard basis $\{\ket{0}, \ket{1}\}$. Then,
\begin{equation*}
M(\ket{\psi})={M(\ket{\psi})}^T=\frac{1}{\sqrt{3}}\left(\begin{smallmatrix}1 & 1\\1 & 0\end{smallmatrix}\right).
\end{equation*}
 Unfortunately, the image of this basis under ${M(\ket{\psi})}^T$ is not orthogonal, exactly because ${M(\ket{\psi})}^T$ is not a scalar multiple of a unitary matrix.
 
 By Lemma \ref{end state lemma} after Alice's measurement, if Alice observes outcome $1$, her end state is $\ket{0}$, in which case the composite system is in state $\ket{\varphi}\otimes \ket{\theta}=\ket{0}\otimes\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$.  If Alice observes outcome $2$, her end state is $\ket{1}$, in which case the composite system is in state $\ket{\varphi}\otimes \ket{\theta}=\ket{1}\otimes \ket{0}$.
 
 The main point is that even though Bob's potential end states
 \begin{equation*}
 \{\ket{\theta_1},\ket{\theta_2}\}=\{\frac{1}{\sqrt{2}}(\ket{0}+\ket{1}),\ket{0} \}
 \end{equation*}
 are a basis, they are not orthogonal.  Thus Bob cannot access his end states by measuring without introducing error as in {\bf{Example}} \ref{example: non-orthogonal states for measurements}.  Note that Bob can "keep" one of the end states and use Gram-Schmidt to complete to an orthonormal basis, for example $\{\ket{0}^\perp, \ket{0}\}=\{\ket{1},\ket{0}\}$.  If Bob measures with respect to this basis, then if Alice observes outcome $2$, the composite system has end state $\ket{1}\otimes \ket{0}$, in which case Bob correctly measures outcome $2$ and end state $\ket{0}$.  On the other hand, if Alice observes outcome $1$, the composite system has end state $\ket{0}\otimes\frac{1}{\sqrt{2}}(\ket{0}+\ket{1})$, in which case Bob observes outcomes $1$ and $2$ each with equal probability.  Because of this, Bob cannot determine Alice's outcome with certainty.  It's worth noting that in the case when he observes the outcome $1$, he will always correctly determine Alice's outcome.


\end{example}



With {\bf{Examples}} \ref{example good} and \ref{example bad} in mind, we now characterize all composite qubit states that allow Bob to determine Alice's measurement end state with certainty.  
\begin{prop}
\label{classification}
Let $\ket{\psi} \in {\mathbb{C}}^2 \otimes {\mathbb{C}}^2$ be a composite state shared by Alice and Bob.  Then, Bob can determine Alice's measurement outcome with certainty if and only if $\ket{\psi}=\frac{1}{\sqrt{2}}(a\ket{00}+(-e^{i\theta})\Bar{b}\ket{01}+b\ket{10}+e^{i\theta}\Bar{a}\ket{11})$, where $a, b \in \mathbb{C}$ with $|a|^2+|b|^2=1$.
\end{prop}
{\bf{Proposition}} \ref{classification} follows from {\bf{Proposition}} \ref{prop: ultimate} and the well known characterization of all $2$ by $2$ unitary matrices.


%----------------------------------------------------------------------------------------
%	SECTION 4
%----------------------------------------------------------------------------------------
\pagebreak

\textcolor{blue}{Need to add some here.  Also maybe add a diagram or a series of diagram} \textcolor{green}{done}
\textcolor{red}{use Alice and Bob diagrams and a paragraph with an intro about the ideas}
\section{Application to a One-time Pad}
Recall one-time pad, as defined in \textbf{Definition \ref{def: classical one-time pad scheme}}. Say Alice wants to transmit an m-digit long message to Bob, she will need to create a one-time pad, which is a private key between Alice and Bob that is also m-digit long. The above classification of entanglement can potentially be used in the following cryptographic scheme.
\begin{enumerate}
    \item Bob creates a series of maximally entangled (as defined in \textbf{Definition \ref{def: maximally entangled}}) 2-qudit states $L={\ket{\psi_1}, \ket{\psi_2}, \hdots, \ket{\psi_m}}$, where $\ket{\psi_i} \in \mathbb{C}^n \otimes \mathbb{C}^n$. He sends the left qudit of each state to Alice via a secure quantum communication channel and keep the right side to himself.
    \item Via a classical communication channel that doesn't have to be secure, Alice notify Bob in order the set of orthonormal bases that she is going to make measurements with. In other words, for each $\ket{\psi_i}$, Alice randomly chooses an orthonormal basis $B_i=\{\ket{b_1}, \ket{b_2}, \hdots, \ket{b_n}\}$ and sends the elements in the basis in order to Bob.
    \item For each qudit received from L, Alice makes a measurement and saves her result locally. With the knowledge of L and $B_1, B_2, \hdots, B_m$, Bob will be able to infer Alice's measurement result by measuring with respect to basis $\{M(\ket{\psi_i})^T \ket{b_1}, M(\ket{\psi_i})^T \ket{b_2}, \hdots, M(\ket{\psi_i})^T \ket{b_n}\}$. He saves the result for each $\ket{\psi_i}$ and in the end get an m-digit long key that can be used for one-time pad introduced in \textbf{Definition \ref{def: quantum one-time pad}}.
\end{enumerate}